{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e990c768-94d2-4265-b152-b2d38ecee76f",
   "metadata": {},
   "source": [
    "# Loading the dependencies and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68a3405c-9bb8-4678-927e-56f594a185da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.linear_model import BayesianRidge, Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import BayesianRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c4239e2-55c6-46d2-9ddd-14a54af93a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import missingno as mno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6714935c-7d49-4e40-a367-3f8c9d0dace7",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e8578bb-03a4-4930-a125-102808e76a07",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/mac/Desktop/Summer_2023/datathon/paper_methods/pulseox_dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m csv_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/mac/Desktop/Summer_2023/datathon/paper_methods/pulseox_dataset.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Read the CSV file using Pandas\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m df_initial \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml/lib/python3.9/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml/lib/python3.9/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml/lib/python3.9/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml/lib/python3.9/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml/lib/python3.9/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/mac/Desktop/Summer_2023/datathon/paper_methods/pulseox_dataset.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to your CSV file\n",
    "csv_path = '/Users/mac/Desktop/Summer_2023/datathon/paper_methods/pulseox_dataset.csv'\n",
    "\n",
    "# Read the CSV file using Pandas\n",
    "df_initial = pd.read_csv(csv_path, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d4fc1e-3bdc-4440-83d5-4e98a6d08d28",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4e66b2-0e69-45cb-bf7c-83bebb85aade",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44697473-63e5-44f4-98bf-0c0311dd8e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6899a9-fa3a-4ff1-84aa-f29ea82f69f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume 'df_initial' is your DataFrame\n",
    "column_names = df_initial.columns.tolist()\n",
    "\n",
    "print(\"Column names:\", column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d511f5-bc3d-4775-a7a4-8038fa27b358",
   "metadata": {},
   "source": [
    "## Keeping relevant columns only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f3c380-cd33-4cc0-96ea-0a4e5e1f8dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to keep (N.B I removed subject_id) \n",
    "columns_to_keep = ['hospital_admission_id', 'source_db', 'admission_age', 'sex_female', 'weight_admission', 'height_admission', 'BMI_admission', 'los_hospital', 'los_ICU', 'comorbidity_score_name', 'comorbidity_score_value', 'in_hospital_mortality', 'race_ethnicity', 'pH', 'pCO2', 'pO2', 'SaO2', 'SpO2', 'vitals_tempc', 'cbc_hemoglobin', 'bmp_sodium', 'bmp_bicarbonate', 'bmp_creatinine', 'sofa_past_overall_24hr', 'sofa_past_cardiovascular_24hr']\n",
    "\n",
    "# Select only the columns you want to keep\n",
    "df_filtered = df_initial[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9239ed87-a9d6-4c98-87a4-95c38b7c6bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20e2fea-228c-431c-a0c6-a932a10f2c28",
   "metadata": {},
   "source": [
    "## Computing p50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1068647-74a9-40ba-beb6-f43874a68c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Copy to ensure no modification of a slice of the original DataFrame\n",
    "df_filtered = df_filtered.copy()\n",
    "df_filtered.loc[:, 'p50'] = ((100 * (df_filtered['pO2']**2.711) / df_filtered['SpO2']) - (df_filtered['pO2']**2.711))**(1/2.711)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f60224-34d2-4345-843c-86ba885441ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking our new list of columns \n",
    "column_names_withp50 = df_filtered.columns.tolist()\n",
    "\n",
    "print(\"Column names:\", column_names_withp50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e722e1-e42f-4852-95ed-36b21ed5ccfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d578cfc2-62b3-46ca-82e4-bf60fe42d20b",
   "metadata": {},
   "source": [
    "## Handling outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153f6fb3-2698-48b5-bf26-0ec8b4aa260f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify and handle potentially erroneous or extreme values in the specified columns by replacing them with NaN.\n",
    "df_filtered.loc[df_filtered[\"pCO2\"] == 0.0, \"pCO2\"] = np.NAN # for pCO2 = 0 \n",
    "df_filtered.loc[df_filtered[\"pH\"] > 8.0, \"pH\"] = np.NAN # for pH>8 \n",
    "df_filtered.loc[df_filtered[\"cbc_hemoglobin\"] > 30.0, \"cbc_hemoglobin\"] = np.NAN # for cbc_hemoglobin > 30.0\n",
    "\n",
    "# only keep 10 < p50< 100\n",
    "# instead of replacing with NaNs just remove the nonvalid entries \n",
    "df_filtered = df_filtered.loc[(df_filtered['p50'] >= 10) & (df_filtered['p50'] <= 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e627ee38-e0ed-43ab-9ff8-517339d43393",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8581d7b-1936-4443-b18e-3804890c6ba5",
   "metadata": {},
   "source": [
    "## Handling Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377eda42-cd61-417a-a393-a5ab2518c9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the entire DataFrame\n",
    "missing_values = df_filtered.isna()  # or df.isnull() \n",
    "\n",
    "# Check if there are any missing values in the entire DataFrame\n",
    "if missing_values.any().any():\n",
    "    print(\"There are missing values in the DataFrame.\")\n",
    "else: \n",
    "    print(\"There are no missing values in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefa4980-ae26-4afc-b5ed-2c7dc64417dc",
   "metadata": {},
   "source": [
    "### Find the percentage of missing values per column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee57f021-d911-4faf-8bdb-56f2d594a9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of missing values per column\n",
    "missing_values_count = df_filtered.isna().sum()\n",
    "\n",
    "# Calculate the total number of cells in the DataFrame\n",
    "total_cells = df_filtered.size\n",
    "\n",
    "# Calculate the total number of missing values in the entire DataFrame\n",
    "total_missing_values = missing_values_count.sum()\n",
    "\n",
    "# Calculate the total percentage of missing values in the entire DataFrame\n",
    "total_percentage_missing = (total_missing_values / total_cells) * 100\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "missing_data_summary = pd.DataFrame({\n",
    "    'Column': df_filtered.columns,\n",
    "    'Percentage Missing (%)': (missing_values_count / len(df_filtered)) * 100\n",
    "})\n",
    "\n",
    "# Print the missing data summary\n",
    "print(missing_data_summary)\n",
    "\n",
    "# Print the total percentage of missing values in the entire DataFrame\n",
    "print(\"Total Percentage Missing in DataFrame: {:.2f}%\".format(total_percentage_missing))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da1037b-4469-4a10-a41c-c0caf21696fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of rows (patients) with at least one missing value\n",
    "percentage_rows_with_missing = (df_filtered.isnull().any(axis=1).sum() / len(df_filtered)) * 100\n",
    "\n",
    "# Print the percentage of rows with at least one missing value\n",
    "print(\"Percentage of rows with at least one missing value: {:.2f}%\".format(percentage_rows_with_missing))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11b8b0e-055e-4e66-ac96-1acfff7e145b",
   "metadata": {},
   "source": [
    "### Drop missing values for the columns with < 5% missing values \n",
    "Columns: admission_age, weight_admission, height_admission, BMI_admission, comorbidity_score_value, in_hospital_mortality, pH, pCO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffd8034-50f7-4355-b8e3-845af577ce7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_1 = df_filtered.dropna(subset=[\"sofa_past_overall_24hr\", \"admission_age\", \"weight_admission\", \"height_admission\",\"BMI_admission\", \"comorbidity_score_value\", \"in_hospital_mortality\", \"pH\", \"pCO2\"])\n",
    "\n",
    "# for now dropping sofa_past_overall_24hr even if 20% of the column is missing -> need to consider another approach later !!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfc853a-978e-449d-9206-f6b499b19b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecffc0d-8a35-475f-b784-608555064d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of missing values per column\n",
    "missing_values_count = df_filtered_1.isna().sum()\n",
    "\n",
    "# Calculate the total number of cells in the DataFrame\n",
    "total_cells = df_filtered_1.size\n",
    "\n",
    "# Calculate the total number of missing values in the entire DataFrame\n",
    "total_missing_values = missing_values_count.sum()\n",
    "\n",
    "# Calculate the total percentage of missing values in the entire DataFrame\n",
    "total_percentage_missing = (total_missing_values / total_cells) * 100\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "missing_data_summary = pd.DataFrame({\n",
    "    'Column': df_filtered.columns,\n",
    "    'Percentage Missing (%)': (missing_values_count / len(df_filtered)) * 100\n",
    "})\n",
    "\n",
    "# Print the missing data summary\n",
    "print(missing_data_summary)\n",
    "\n",
    "# Print the total percentage of missing values in the entire DataFrame\n",
    "print(\"Total Percentage Missing in DataFrame: {:.2f}%\".format(total_percentage_missing))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fbd4e1-ad25-4838-bd21-01f5d03f2157",
   "metadata": {},
   "source": [
    "### Imputation of missing values using regression for columns with missing values >5%\n",
    "Columns: vitals_tempc, cbc_hemoglobin, bmp_sodium, bmp_bicarbonate, bmp_creatinine, sofa_past_overall_24hr, sofa_past_cardiovascular_24hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3923a0-b852-4198-bfa3-7724d01913fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_vars = [\"vitals_tempc\", \"cbc_hemoglobin\", \"bmp_sodium\", \"bmp_bicarbonate\", \"bmp_creatinine\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24b6ae3-dcc8-4931-ba69-b5af7ef01c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_vars = ['admission_age', 'sex_female', 'comorbidity_score_value', 'sofa_past_overall_24hr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54fd5af-21df-4eda-9a91-4c9b62f9cd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Create an IterativeImputer with a higher number of iterations\n",
    "imputer = IterativeImputer(estimator=KNeighborsRegressor(), max_iter=10)  # You can adjust the value as needed\n",
    "\n",
    "# Fit and transform the imputer on df_filtered_1\n",
    "imputed_df_final = imputer.fit_transform(df_filtered_1[predictor_vars + missing_vars])\n",
    "\n",
    "# Update the original DataFrame using .loc\n",
    "df_filtered_1.loc[:, missing_vars] = imputed_df_final[:, -len(missing_vars):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36515a81-a0ea-4c92-9f07-3de1f45197bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aims to identify and handle potentially erroneous or extreme values in the specified columns by replacing them with NaN.\n",
    "# Count missing values in each column\n",
    "missing_counts = df_filtered_1.isna().sum()\n",
    "print(missing_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069b0f36-1e01-41e3-b103-c3c4c78c6a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c02ac01-9867-4c67-b0a8-cdb6a7173a50",
   "metadata": {},
   "source": [
    "## Cohort Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f9b331-e93b-42fa-b246-b24f8d478955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique values from a specific column\n",
    "unique_values = df_filtered_1['race_ethnicity'].unique()\n",
    "\n",
    "# Print the unique values\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb3e881-af7b-45ba-b0a1-508c04e2bfc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Filter the DataFrame to include only rows where source_db is 'eicu'\n",
    "filtered_df = df_filtered_1[df_filtered_1[\"source_db\"] == \"eicu\"].copy()\n",
    "\n",
    "# Create a 'Gender' column based on 'sex_female'\n",
    "filtered_df['Gender'] = filtered_df['sex_female'].map({0: 'Male', 1: 'Female'})\n",
    "\n",
    "# Group the data by 'Gender' and 'race_ethnicity' and calculate the percentage\n",
    "result = filtered_df.groupby(['Gender', 'race_ethnicity']).size() / len(filtered_df) * 100\n",
    "\n",
    "# Reset the index to create a DataFrame\n",
    "result = result.reset_index(name='Percentage')\n",
    "\n",
    "# Pivot the DataFrame to have columns for females and males\n",
    "pivot_table = result.pivot(index='race_ethnicity', columns='Gender', values='Percentage')\n",
    "\n",
    "# Fill NaN values with 0\n",
    "pivot_table = pivot_table.fillna(0)\n",
    "\n",
    "# Display the table\n",
    "print(pivot_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b541ef7c-09a9-4d12-b2f0-de772fd8ceb9",
   "metadata": {},
   "source": [
    "## Profile Report\n",
    "Provides a summary of descriptive statistics and insights about a dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8006f8-e1ea-4c23-b211-e923d3d0cf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "# Create a profile report\n",
    "# profile = ProfileReport(df_filtered_1)\n",
    "\n",
    "# Save the report to an HTML file\n",
    "# profile.to_file('report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69f1dc5-9556-42f2-9a37-af6e61f6a420",
   "metadata": {},
   "source": [
    "## Variable encoding\n",
    "Variable encoding, also known as feature encoding or categorical encoding, is a fundamental preprocessing step in machine learning and data analysis. Its goal is to convert categorical variables (features) into a numerical format that machine learning algorithms can work with effectively. Categorical variables are those that represent categories or labels rather than numerical quantities. Encoding categorical variables is essential because many machine learning algorithms require numerical input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022bca36-077f-4d13-9ef3-d322e46d6aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique values from a specific column\n",
    "unique_values = df_filtered_1['race_ethnicity'].unique()\n",
    "\n",
    "# Print the unique values\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1729e890-bd57-420a-ada8-b28e736511e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Select columns with non-numeric data types\n",
    "non_numeric_columns = df_filtered_1.select_dtypes(exclude=['number'])\n",
    "\n",
    "# Check if there are any non-numeric columns\n",
    "if non_numeric_columns.empty:\n",
    "    print(\"All values are numerical.\")\n",
    "else:\n",
    "    print(\"Non-numeric columns found:\")\n",
    "    print(non_numeric_columns)\n",
    "\n",
    "    # Count occurrences of each unique value in non-numeric columns\n",
    "    for column in non_numeric_columns:\n",
    "        value_counts = df_filtered_1[column].value_counts()\n",
    "        print(f\"Occurrences in '{column}':\")\n",
    "        print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d958cce8-5589-4897-a9e8-6310b26b0e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_filtered_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8981852-9144-446a-b47b-11f1fc691dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['race_ethnicity'], prefix='ethnicity')\n",
    "df = pd.get_dummies(df, columns=['source_db'], prefix='source')\n",
    "df = pd.get_dummies(df, columns=['comorbidity_score_name'], prefix='comorbidity_score_name')\n",
    "# N.B: we are only interested in Charlson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95701a38-c899-470b-bf19-78789adf455e",
   "metadata": {},
   "source": [
    "## Final Shape of the dataframe used for statistical modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41096b6-e93f-4641-9fda-b83ef92645c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e850c77e-1ce8-4ba9-bf2e-a783f1279c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see all the columns in the DataFrame\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23602462-a082-4f64-aaec-d43d010ee51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Load your original dataset into a DataFrame\n",
    "# Replace 'original_dataset.csv' with your dataset file path\n",
    "# df = pd.read_csv('original_dataset.csv')\n",
    "\n",
    "# Select the columns of interest for your analysis\n",
    "columns_of_interest = ['admission_age', 'sex_female', 'sofa_past_overall_24hr', 'comorbidity_score_name_Charlson', 'los_ICU', 'los_hospital', 'in_hospital_mortality']\n",
    "\n",
    "# Create separate DataFrames for survivor and non-survivor cohorts\n",
    "survivor_df = df[df['in_hospital_mortality'] == 0]  # 0 for survivors\n",
    "non_survivor_df = df[df['in_hospital_mortality'] == 1]  # 1 for non-survivors\n",
    "\n",
    "# Calculate and format the statistics for each variable\n",
    "stats_summary = []\n",
    "\n",
    "for column in columns_of_interest[:-1]:  # Excluding 'in_hospital_mortality' column\n",
    "    mean_survivor = survivor_df[column].mean()\n",
    "    mean_non_survivor = non_survivor_df[column].mean()\n",
    "    p_value = stats.ttest_ind(survivor_df[column], non_survivor_df[column]).pvalue\n",
    "\n",
    "    stats_summary.append((column, mean_survivor, mean_non_survivor, p_value))\n",
    "\n",
    "# Table column headers\n",
    "table_headers = [\n",
    "    \"Variable\", \"Survivor Mean\", \"Non-Survivor Mean\", \"p-value\"\n",
    "]\n",
    "\n",
    "# Table content\n",
    "table_content = []\n",
    "\n",
    "for stat in stats_summary:\n",
    "    variable, mean_survivor, mean_non_survivor, p_value = stat\n",
    "    table_content.append([variable, f\"{mean_survivor:.2f}\", f\"{mean_non_survivor:.2f}\", f\"{p_value:.3f}\"])\n",
    "\n",
    "# Print the table\n",
    "total_patients = len(df)\n",
    "print(f'A total of {total_patients} patients were included in the final analysis from the original dataset of {total_patients} patients.')\n",
    "\n",
    "# Print table headers\n",
    "print(\"{:<30} {:<20} {:<20} {:<20}\".format(*table_headers))\n",
    "\n",
    "# Print table content\n",
    "for row in table_content:\n",
    "    print(\"{:<30} {:<20} {:<20} {:<20}\".format(*row))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062e2615-44cf-45f3-a812-ccad8edcbd09",
   "metadata": {},
   "source": [
    "# Statistical Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ea2ba3-16e8-4322-9c36-5e9562141587",
   "metadata": {},
   "source": [
    "## Compare mortality group\n",
    "Note: \n",
    "* Mortality 1 -> patient passed away\n",
    "* Mortality 0 -> patient survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edc26a1-9843-4ccc-9730-dce4c668499b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['in_hospital_mortality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fed5ff8-3163-45f2-a579-75548d8677ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "mortality_comparison = df['in_hospital_mortality'].value_counts().reset_index()\n",
    "mortality_comparison.columns = ['Mortality', 'Count']\n",
    "print(\"Comparing Mortality Groups:\")\n",
    "print(mortality_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e94a664-a73c-4ae5-a043-0ec1bb9c1926",
   "metadata": {},
   "source": [
    "## Compare Mortality groups with p50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d4909d-6948-4974-b56e-03ec253b74af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4494bc-cb20-4ced-b682-b71cb02de014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234d2faa-07b0-4be6-bf23-28909bb0dc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to categorize 'p50' values into groups\n",
    "def p50_category(p50_value):\n",
    "    if p50_value > 30:\n",
    "        return 'Right Shift'\n",
    "    elif 22 <= p50_value <= 30:\n",
    "        return 'Normal'\n",
    "    else:\n",
    "        return 'Left Shift'\n",
    "\n",
    "# Apply the categorization function to create a new column 'p50_group'\n",
    "df['p50_group'] = df['p50'].apply(p50_category)\n",
    "\n",
    "# Group by 'in_hospital_mortality' and 'p50_group' and calculate the count for each group\n",
    "group_comparison = df.groupby(['in_hospital_mortality', 'p50_group']).size().reset_index(name='Count')\n",
    "\n",
    "print(\"Comparing Mortality and Different Groups of p50:\")\n",
    "print(group_comparison)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1856ce47-0b6e-48c8-b647-7723e5d339dc",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b49ef21-b784-40d2-b0c5-f9dd55db690e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# matplotlib.use('tkagg')  # Use Tkinter backend\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# # Convert 'in_hospital_mortality' to strings ('0' or '1')\n",
    "# df['in_hospital_mortality'] = df['in_hospital_mortality'].astype(str)\n",
    "\n",
    "# Create a count plot to compare 'p50_group' categories with respect to mortality\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='p50_group', hue='in_hospital_mortality', data=df, palette='Set3', order=['Left Shift', 'Normal', 'Right Shift'])\n",
    "plt.title('Count Plot of p50_group by Mortality')\n",
    "plt.xlabel('p50_group')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Mortality', labels=['Survivors', 'Non-Survivors'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e684e76-acb4-400e-942c-bb3b390cd483",
   "metadata": {},
   "source": [
    "## pH, pCO2, and HCO3 Grouping and Box Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84c4d18-e427-499a-b2d7-5111933538b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Define pH groups\n",
    "def get_pH_group(pH):\n",
    "    if pH < 7.0:\n",
    "        return 'Gr1:pH<7.0'\n",
    "    elif pH < 7.2:\n",
    "        return 'Gr2:pH7.0-7.2'\n",
    "    elif pH < 7.35:\n",
    "        return 'Gr3:pH7.2-7.35'\n",
    "    elif pH < 7.45:\n",
    "        return 'Gr4:pH7.35-7.45'\n",
    "    elif pH < 7.6:\n",
    "        return 'Gr5:pH7.45-7.6'\n",
    "    else:\n",
    "        return 'Gr6:pH>7.6'\n",
    "\n",
    "# Apply grouping functions to create new columns\n",
    "df['pHGr'] = df['pH'].apply(get_pH_group)\n",
    "\n",
    "# Specify the order of pHGr categories\n",
    "order = ['Gr1:pH<7.0', 'Gr2:pH7.0-7.2', 'Gr3:pH7.2-7.35', 'Gr4:pH7.35-7.45', 'Gr5:pH7.45-7.6', 'Gr6:pH>7.6']\n",
    "\n",
    "# Create a box plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='pHGr', y='p50', data=df, palette='Set3', order=order)\n",
    "plt.ylim(0, 60)\n",
    "plt.title('Box Plot of p50 by pH Group')\n",
    "plt.xlabel('pH Group')\n",
    "plt.ylabel('p50')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1128f9c6-2f11-4fbb-8986-6869c8ec4c74",
   "metadata": {},
   "source": [
    "## ANOVA and Box Plot for pCO2 Groups vs. p50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd9ba64-7e13-4223-b43b-1b6cdb4e359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Define pCO2 groups\n",
    "def get_pCO2_group(pCO2):\n",
    "    if pCO2 < 20:\n",
    "        return 'Gr1:pCO2<20'\n",
    "    elif pCO2 < 35:\n",
    "        return 'Gr2:pCO2:20-35'\n",
    "    elif pCO2 < 45:\n",
    "        return 'Gr3:pCO2:35-45'\n",
    "    elif pCO2 < 60:\n",
    "        return 'Gr4:pCO2:45-60'\n",
    "    elif pCO2 < 90:\n",
    "        return 'Gr5:pCO2:60-90'\n",
    "    elif pCO2 < 120:\n",
    "        return 'Gr6:pCO2:90-120'\n",
    "    else:\n",
    "        return 'Gr7:pCO2>120'\n",
    "\n",
    "# Apply grouping functions to create new columns\n",
    "df['pCO2Gr'] = df['pCO2'].apply(get_pCO2_group)\n",
    "\n",
    "# Perform ANOVA\n",
    "model = ols('p50 ~ C(pCO2Gr)', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Display ANOVA results\n",
    "print(anova_table)\n",
    "\n",
    "# Create a box plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='pCO2Gr', y='p50', data=df, palette='Set3')\n",
    "plt.ylim(0, 60)\n",
    "plt.title('Box Plot of p50 by pCO2 Group')\n",
    "plt.xlabel('pCO2 Group')\n",
    "plt.ylabel('p50')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3915b4f-c11f-45ea-a1dd-799b7938e509",
   "metadata": {},
   "source": [
    "## ANOVA and Box Plot for HCO3 Groups vs. p50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6f1407-6c5a-4867-ab81-18764fca1703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "\n",
    "# Define pCO2 groups\n",
    "def get_pCO2_group(pCO2):\n",
    "    if pCO2 < 20:\n",
    "        return 'Gr1:pCO2<20'\n",
    "    elif pCO2 < 35:\n",
    "        return 'Gr2:pCO2:20-35'\n",
    "    elif pCO2 < 45:\n",
    "        return 'Gr3:pCO2:35-45'\n",
    "    elif pCO2 < 60:\n",
    "        return 'Gr4:pCO2:45-60'\n",
    "    elif pCO2 < 90:\n",
    "        return 'Gr5:pCO2:60-90'\n",
    "    elif pCO2 < 120:\n",
    "        return 'Gr6:pCO2:90-120'\n",
    "    else:\n",
    "        return 'Gr7:pCO2>120'\n",
    "\n",
    "# Apply grouping functions to create new columns\n",
    "df['pCO2Gr'] = df['pCO2'].apply(get_pCO2_group)\n",
    "\n",
    "# Perform ANOVA\n",
    "model = ols('p50 ~ C(pCO2Gr)', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Display ANOVA results\n",
    "print(anova_table)\n",
    "\n",
    "# Create a box plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='pCO2Gr', y='p50', data=df, palette='Set3')\n",
    "plt.ylim(0, 60)\n",
    "plt.title('Box Plot of p50 by pCO2 Group')\n",
    "plt.xlabel('pCO2 Group')\n",
    "plt.ylabel('p50')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4faef6-6033-4c88-9029-b3a22bb53ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "\n",
    "p50df = df\n",
    "\n",
    "# Define HCO3 groups\n",
    "def get_HCO3_group(bmp_bicarbonate):\n",
    "    if bmp_bicarbonate < 8:\n",
    "        return 'Gr1:HCO3<8'\n",
    "    elif bmp_bicarbonate < 18:\n",
    "        return 'Gr2:HCO3:8-18'\n",
    "    elif bmp_bicarbonate < 24:\n",
    "        return 'Gr3:HCO3:18-24'\n",
    "    elif bmp_bicarbonate < 28:\n",
    "        return 'Gr4:HCO3:24-28'\n",
    "    elif bmp_bicarbonate < 35:\n",
    "        return 'Gr5:HCO3:28-35'\n",
    "    else:\n",
    "        return 'Gr6:HCO3>35'\n",
    "\n",
    "# Apply grouping functions to create a new column\n",
    "p50df['HCO3Gr'] = p50df['bmp_bicarbonate'].apply(get_HCO3_group)\n",
    "\n",
    "# Perform ANOVA\n",
    "model = ols('p50 ~ C(HCO3Gr)', data=p50df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Display ANOVA results\n",
    "print(anova_table)\n",
    "\n",
    "# Create a box plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='HCO3Gr', y='p50', data=p50df, palette='Set3')\n",
    "plt.ylim(0, 60)\n",
    "plt.title('Box Plot of p50 by HCO3 Group')\n",
    "plt.xlabel('HCO3 Group')\n",
    "plt.ylabel('p50')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd6b14e-110b-4331-a4bd-0b7942955a30",
   "metadata": {},
   "source": [
    "## Scatter Plot with Non-Straight Regression Lines and Darker Color for Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb41a897-7519-4e43-b33b-80c9018399c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "p50df = df\n",
    "\n",
    "# Define a function to categorize p50 values\n",
    "def p50_category(p50_value):\n",
    "    if p50_value > 30:\n",
    "        return 'Right Shift'\n",
    "    elif 22 <= p50_value <= 30:\n",
    "        return 'Normal'\n",
    "    else:\n",
    "        return 'Left Shift'\n",
    "\n",
    "# Add the p50Gr column to the DataFrame\n",
    "p50df['p50Gr'] = p50df['p50'].apply(p50_category)\n",
    "\n",
    "# Linear regression models\n",
    "model1 = ols('p50 ~ C(pHGr) + C(pCO2Gr) + C(HCO3Gr)', data=p50df).fit()\n",
    "model2 = ols('p50 ~ pH + pCO2 + bmp_bicarbonate', data=p50df).fit()\n",
    "\n",
    "# Recreate scatter plot with non-straight regression lines for different categories\n",
    "plt.figure(figsize=(10, 6))\n",
    "palette = sns.color_palette(\"husl\", len(p50df['p50Gr'].unique()))\n",
    "\n",
    "for category, color in zip(p50df['p50Gr'].unique(), palette):\n",
    "    category_data = p50df[p50df['p50Gr'] == category]\n",
    "\n",
    "    # Choose a darker shade of the same color for the line\n",
    "    line_color = sns.set_hls_values(color, l=0.3)\n",
    "\n",
    "    sns.regplot(\n",
    "        x='pO2',\n",
    "        y='SpO2',\n",
    "        data=category_data,\n",
    "        color=line_color,\n",
    "        label=category,\n",
    "        lowess=True,  # Use lowess regression for non-straight lines\n",
    "        scatter=False,  # Hide scatter points in the regression line\n",
    "        line_kws={'lw': 2}  # Adjust line thickness as needed\n",
    "    )\n",
    "\n",
    "    sns.scatterplot(\n",
    "        x='pO2',\n",
    "        y='SpO2',\n",
    "        data=category_data,\n",
    "        color=color,\n",
    "        label=f'{category} Dots',\n",
    "        s=60  # Adjust the size of the dots as needed\n",
    "    )\n",
    "\n",
    "plt.title('Scatter Plot with Non-Straight Regression Lines and Darker Color for Lines')\n",
    "plt.xlabel('pO2')\n",
    "plt.ylabel('SpO2')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617df6ce-595d-4ee7-b811-1b4f51cf6633",
   "metadata": {},
   "source": [
    "## ANOVA on admission_age, comorbidity_score_value, sofa_past_overall_24hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c8367a-16c4-481c-bdd8-55b061c629ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.discrete.discrete_model import Logit\n",
    "from lifelines import KaplanMeierFitter\n",
    "import scipy.stats as stats\n",
    "\n",
    "p50df = df\n",
    "\n",
    "# Define a function to categorize p50 values\n",
    "def p50_category(p50_value):\n",
    "    if p50_value > 30:\n",
    "        return 'Right Shift'\n",
    "    elif 22 <= p50_value <= 30:\n",
    "        return 'Normal'\n",
    "    else:\n",
    "        return 'Left Shift'\n",
    "\n",
    "# Create the p50Gr variable based on the p50_category function\n",
    "p50df['p50Gr'] = p50df['p50'].apply(p50_category)\n",
    "\n",
    "# Perform ANOVA on admission_age\n",
    "model_age = ols('admission_age ~ p50Gr', data=p50df).fit()\n",
    "anova_age = anova_lm(model_age)\n",
    "\n",
    "print(\"\\nANOVA on admission_age:\")\n",
    "print(anova_age)\n",
    "\n",
    "# Perform ANOVA on comorbidity_score_value\n",
    "model_comorbidity = ols('comorbidity_score_value ~ p50Gr', data=p50df).fit()\n",
    "anova_comorbidity = anova_lm(model_comorbidity)\n",
    "\n",
    "print(\"\\nANOVA on comorbidity_score_value:\")\n",
    "print(anova_comorbidity)\n",
    "\n",
    "# Perform ANOVA on sofa_past_overall_24hr\n",
    "model_sofa = ols('sofa_past_overall_24hr ~ p50Gr', data=p50df).fit()\n",
    "anova_sofa = anova_lm(model_sofa)\n",
    "\n",
    "print(\"\\nANOVA on sofa_past_overall_24hr:\")\n",
    "print(anova_sofa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba2263d-dc8e-4570-8c5e-958c82108977",
   "metadata": {},
   "source": [
    "## Chi-squared test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f6978b-408c-43ea-b863-ca894c66fb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-squared test for p50Gr and sex_female\n",
    "chisq_sex = stats.chi2_contingency(pd.crosstab(p50df['p50Gr'], p50df['sex_female']))\n",
    "\n",
    "print(\"\\nChi-squared test for p50Gr and sex_female:\")\n",
    "print(f\"Chi-squared = {chisq_sex[0]:.3f}, p-value = {chisq_sex[1]:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822ad76b-9b59-44a1-af9d-b5f9eee4d422",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7195594a-ce3f-49f3-b10d-a952d636bc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from lifelines import KaplanMeierFitter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'in_hospital_mortality' is the name of your column\n",
    "df['in_hospital_mortality'] = pd.to_numeric(df['in_hospital_mortality'], errors='coerce')\n",
    "df['in_hospital_mortality'] = df['in_hospital_mortality'].fillna(0).astype(int)\n",
    "\n",
    "# Logistic Regression Model 1\n",
    "formula1 = \"in_hospital_mortality ~ sofa_past_overall_24hr + comorbidity_score_value + admission_age\"\n",
    "model1 = sm.Logit.from_formula(formula1, data=df)\n",
    "result1 = model1.fit()\n",
    "\n",
    "# Logistic Regression Model 2\n",
    "formula2 = \"in_hospital_mortality ~ p50 + sofa_past_overall_24hr + comorbidity_score_value + admission_age\"\n",
    "model2 = sm.Logit.from_formula(formula2, data=df)\n",
    "result2 = model2.fit()\n",
    "\n",
    "# Summarize Model 1\n",
    "print(\"Logistic Regression Model 1:\")\n",
    "print(result1.summary())\n",
    "\n",
    "# Calculate and print odds ratios for Model 1\n",
    "params_model1 = result1.params\n",
    "conf_int_model1 = result1.conf_int()\n",
    "conf_int_model1['Odds Ratio'] = params_model1\n",
    "conf_int_model1.columns = ['2.5%', '97.5%', 'Odds Ratio']\n",
    "odds_ratios_model1 = np.exp(conf_int_model1)\n",
    "\n",
    "# Round numeric columns\n",
    "odds_ratios_model1['Odds Ratio'] = odds_ratios_model1['Odds Ratio'].round(4)\n",
    "odds_ratios_model1['2.5%'] = odds_ratios_model1['2.5%'].round(4)\n",
    "odds_ratios_model1['97.5%'] = odds_ratios_model1['97.5%'].round(4)\n",
    "\n",
    "# Print the odds ratios for Model 1\n",
    "print(\"\\nOdds Ratios for Model 1:\")\n",
    "print(odds_ratios_model1.to_string(index=False))\n",
    "\n",
    "# Summarize Model 2\n",
    "print(\"Logistic Regression Model 2:\")\n",
    "print(result2.summary())\n",
    "\n",
    "# Calculate and print odds ratios for Model 2\n",
    "params_model2 = result2.params\n",
    "conf_int_model2 = result2.conf_int()\n",
    "conf_int_model2['Odds Ratio'] = params_model2\n",
    "conf_int_model2.columns = ['2.5%', '97.5%', 'Odds Ratio']\n",
    "odds_ratios_model2 = np.exp(conf_int_model2)\n",
    "\n",
    "# Round numeric columns\n",
    "odds_ratios_model2['Odds Ratio'] = odds_ratios_model2['Odds Ratio'].round(4)\n",
    "odds_ratios_model2['2.5%'] = odds_ratios_model2['2.5%'].round(4)\n",
    "odds_ratios_model2['97.5%'] = odds_ratios_model2['97.5%'].round(4)\n",
    "\n",
    "# Print the odds ratios for Model 2\n",
    "print(\"\\nOdds Ratios for Model 2:\")\n",
    "print(odds_ratios_model2.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c39a0c5-572c-4534-9240-f53bf2aaf998",
   "metadata": {},
   "source": [
    "## Kaplan-Meier Survival Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69177869-b1eb-4497-8042-6d61f78a1aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import KaplanMeierFitter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a function to categorize p50 values\n",
    "def p50_category(p50_value):\n",
    "    if p50_value > 30:\n",
    "        return 'Right Shift'\n",
    "    elif 22 <= p50_value <= 30:\n",
    "        return 'Normal'\n",
    "    else:\n",
    "        return 'Left Shift'\n",
    "\n",
    "# Apply the p50 category function to create a new column 'p50_category'\n",
    "df['p50_category'] = df['p50'].apply(p50_category)\n",
    "\n",
    "# Create KaplanMeierFitter\n",
    "kmf = KaplanMeierFitter()\n",
    "\n",
    "# Set up plot colors\n",
    "colors = ['blue', 'green', 'red']\n",
    "\n",
    "# Create subplots\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Set the time range between 0 and 200\n",
    "ax.set_xlim(0, 200)\n",
    "\n",
    "# Fit survival curves and plot with a finer time scale\n",
    "for i, category in enumerate(df['p50_category'].unique()):\n",
    "    mask = (df['p50_category'] == category)\n",
    "    kmf.fit(df['los_hospital'][mask], event_observed=df['in_hospital_mortality'][mask], label=category)\n",
    "\n",
    "    # Plot the survival curve with a step size\n",
    "    kmf.plot(ax=ax, ci_show=False, color=colors[i], linewidth=2, label=category)\n",
    "\n",
    "# Add labels to the axes\n",
    "ax.set_title('Kaplan-Meier Survival Curves')\n",
    "ax.set_xlabel('Time (LOS_Hospital)')\n",
    "ax.set_ylabel('Survival Probability')\n",
    "\n",
    "# Add legend\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80102b0-1855-40d4-b3ea-35a3d995ec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import KaplanMeierFitter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define a function to categorize p50 values\n",
    "def p50_category(p50_value):\n",
    "    if p50_value > 30:\n",
    "        return 'Right Shift'\n",
    "    elif 22 <= p50_value <= 30:\n",
    "        return 'Normal'\n",
    "    else:\n",
    "        return 'Left Shift'\n",
    "\n",
    "# Apply the p50 category function to create a new column 'p50_category'\n",
    "df['p50_category'] = df['p50'].apply(p50_category)\n",
    "\n",
    "# Create KaplanMeierFitter\n",
    "kmf = KaplanMeierFitter()\n",
    "\n",
    "# Set up plot colors\n",
    "colors = ['blue', 'green', 'red']\n",
    "\n",
    "# Create subplots\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Define a custom time grid for smoother curves\n",
    "time_grid = np.linspace(0, 200, 200)  # Adjust the range to 0-200\n",
    "\n",
    "# Plot Kaplan-Meier survival curves with kernel smoothing\n",
    "for i, category in enumerate(df['p50_category'].unique()):\n",
    "    mask = (df['p50_category'] == category)\n",
    "    times = df['los_hospital'][mask]\n",
    "    events = df['in_hospital_mortality'][mask]\n",
    "\n",
    "    # Plot the survival curve with kernel smoothing\n",
    "    kmf.fit(times, event_observed=events, timeline=time_grid, label=category)\n",
    "    kmf.plot(ax=ax, color=colors[i], linewidth=2, ci_alpha=0.2)\n",
    "\n",
    "# Add labels to the axes\n",
    "ax.set_title('Kaplan-Meier Survival Curves')\n",
    "ax.set_xlabel('Time (LOS_Hospital)')\n",
    "ax.set_ylabel('Survival Probability')\n",
    "\n",
    "# Add legend\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3509e204-fe90-4dcb-938e-d0e53e124890",
   "metadata": {},
   "source": [
    "# Analyzing the Impact of p50 on Predicting Hospital Mortality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e0cec1-63d2-455e-a22c-d45d35c94a14",
   "metadata": {},
   "source": [
    "## Simple Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b319d2-03ee-4533-a0fc-cb25d4655382",
   "metadata": {},
   "source": [
    "sofa_past_overall_24hr as a predictor variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c6ce0f-120e-4cb3-807e-b1165713f1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9cfe55-1421-4959-834e-d116037bc9c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Your data preparation code\n",
    "X = df[['sofa_past_overall_24hr']]  # Predictor variable\n",
    "y = df['in_hospital_mortality']  # Target variable\n",
    "\n",
    "# Split data into training, validation, and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cross_val_scores = cross_val_score(model, X_train, y_train, cv=k_fold, scoring='roc_auc')\n",
    "\n",
    "# Train the model on the training data:\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "y_pred = (y_prob > 0.4).astype(int)\n",
    "\n",
    "# Calculate AUC score on the test set\n",
    "auc_score = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "# Number of bootstrap iterations\n",
    "n_iterations = 1000  # You can change this value based on your preference\n",
    "\n",
    "# Create an array to store the AUC values from the bootstrap iterations\n",
    "auc_scores = []\n",
    "\n",
    "for _ in range(n_iterations):\n",
    "    # Sample with replacement from the test data\n",
    "    X_boot, y_boot = resample(X_test, y_test, random_state=42)\n",
    "\n",
    "    # Calculate AUC score on the bootstrapped data\n",
    "    auc = roc_auc_score(y_boot, model.predict_proba(X_boot)[:, 1])\n",
    "    auc_scores.append(auc)\n",
    "\n",
    "# Calculate the confidence interval\n",
    "alpha = 0.95  # You can change this for different confidence levels\n",
    "p = ((1.0-alpha)/2.0) * 100\n",
    "lower = max(0.0, np.percentile(auc_scores, p))\n",
    "p = (alpha+((1.0-alpha)/2.0)) * 100\n",
    "upper = min(1.0, np.percentile(auc_scores, p))\n",
    "\n",
    "# Calculate additional metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print the metrics\n",
    "print(f'AUC Score: {auc_score:.2f}')\n",
    "print(f'95% Confidence Interval: ({lower:.2f}, {upper:.2f})')\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "\n",
    "# Print the confusion matrix \n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874e531b-5b1e-4e8f-9469-a6682fb6c749",
   "metadata": {},
   "source": [
    "## Simple regression with other predictive features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efe776e-8fd6-45d4-b0c7-a9846b8aa9e5",
   "metadata": {},
   "source": [
    "### Without p50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f457ff-2250-4507-84c8-8d09a09ab577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Select relevant columns\n",
    "selected_features = [\n",
    "    'sofa_past_overall_24hr',\n",
    "    'comorbidity_score_value', 'cbc_hemoglobin', 'bmp_sodium', 'admission_age',\n",
    "    'in_hospital_mortality', 'comorbidity_score_name_Charlson', 'comorbidity_score_name_Elixhauser'\n",
    "]\n",
    "\n",
    "# Create a DataFrame with selected features\n",
    "selected_df = df[selected_features]\n",
    "\n",
    "# Split data\n",
    "X = selected_df.drop('in_hospital_mortality', axis=1)\n",
    "y = selected_df['in_hospital_mortality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale our data \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# solver -> specifies the algorithm used for optimizing the logistic regression model \n",
    "# lbfgs -> suitable for small to medium-sized datasets.\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "\n",
    "# K folds cross-validation \n",
    "k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cross_val_scores = cross_val_score(model, X_train_scaled, y_train, cv=k_fold, scoring='roc_auc')\n",
    "\n",
    "# Train the model with the scaled data\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate AUC score on the test set\n",
    "auc_score = roc_auc_score(y_test, model.predict_proba(X_test_scaled)[:, 1])\n",
    "\n",
    "# Number of bootstrap iterations\n",
    "n_iterations = 1000  # You can change this value based on your preference\n",
    "\n",
    "# Create an array to store the AUC values from the bootstrap iterations\n",
    "auc_scores = []\n",
    "\n",
    "for _ in range(n_iterations):\n",
    "    # Sample with replacement from the test data\n",
    "    X_boot, y_boot = resample(X_test_scaled, y_test, random_state=42)\n",
    "\n",
    "    # Calculate AUC score on the bootstrapped data\n",
    "    auc = roc_auc_score(y_boot, model.predict_proba(X_boot)[:, 1])\n",
    "    auc_scores.append(auc)\n",
    "\n",
    "# Calculate the confidence interval\n",
    "alpha = 0.95  # You can change this for different confidence levels\n",
    "p = ((1.0-alpha)/2.0) * 100\n",
    "lower = max(0.0, np.percentile(auc_scores, p))\n",
    "p = (alpha+((1.0-alpha)/2.0)) * 100\n",
    "upper = min(1.0, np.percentile(auc_scores, p))\n",
    "\n",
    "# Calculate various metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Assess the coefficients for the selected features\n",
    "feature_coefficients = model.coef_[0]\n",
    "\n",
    "# Print results\n",
    "print(f'AUC Score: {auc_score:.2f}')\n",
    "print(f'95% Confidence Interval: ({lower:.2f}, {upper:.2f})')\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "\n",
    "for feature, coefficient in zip(X.columns, feature_coefficients):\n",
    "    print(f'Coefficient for {feature}: {coefficient:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db989d77-b22a-4c49-a49d-61768aaf8775",
   "metadata": {},
   "source": [
    "### With p50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928e8405-3741-4913-bf4f-304379bf1f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Select relevant columns\n",
    "selected_features = [ 'p50',\n",
    "    'sofa_past_overall_24hr',\n",
    "    'comorbidity_score_value', 'cbc_hemoglobin', 'bmp_sodium', 'admission_age',\n",
    "    'in_hospital_mortality', 'comorbidity_score_name_Charlson', 'comorbidity_score_name_Elixhauser'\n",
    "]\n",
    "\n",
    "# Create a DataFrame with selected features\n",
    "selected_df = df[selected_features]\n",
    "\n",
    "# Split data\n",
    "X = selected_df.drop('in_hospital_mortality', axis=1)\n",
    "y = selected_df['in_hospital_mortality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale our data \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# solver -> specifies the algorithm used for optimizing the logistic regression model \n",
    "# lbfgs -> suitable for small to medium-sized datasets.\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "\n",
    "# K folds cross-validation \n",
    "k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cross_val_scores = cross_val_score(model, X_train_scaled, y_train, cv=k_fold, scoring='roc_auc')\n",
    "\n",
    "# Train the model with the scaled data\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate AUC score on the test set\n",
    "auc_score = roc_auc_score(y_test, model.predict_proba(X_test_scaled)[:, 1])\n",
    "\n",
    "# Number of bootstrap iterations\n",
    "n_iterations = 1000  # You can change this value based on your preference\n",
    "\n",
    "# Create an array to store the AUC values from the bootstrap iterations\n",
    "auc_scores = []\n",
    "\n",
    "for _ in range(n_iterations):\n",
    "    # Sample with replacement from the test data\n",
    "    X_boot, y_boot = resample(X_test_scaled, y_test, random_state=42)\n",
    "\n",
    "    # Calculate AUC score on the bootstrapped data\n",
    "    auc = roc_auc_score(y_boot, model.predict_proba(X_boot)[:, 1])\n",
    "    auc_scores.append(auc)\n",
    "\n",
    "# Calculate the confidence interval\n",
    "alpha = 0.95  # You can change this for different confidence levels\n",
    "p = ((1.0-alpha)/2.0) * 100\n",
    "lower = max(0.0, np.percentile(auc_scores, p))\n",
    "p = (alpha+((1.0-alpha)/2.0)) * 100\n",
    "upper = min(1.0, np.percentile(auc_scores, p))\n",
    "\n",
    "# Calculate various metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Assess the coefficients for the selected features\n",
    "feature_coefficients = model.coef_[0]\n",
    "\n",
    "# Print results\n",
    "print(f'AUC Score: {auc_score:.2f}')\n",
    "print(f'95% Confidence Interval: ({lower:.2f}, {upper:.2f})')\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "\n",
    "for feature, coefficient in zip(X.columns, feature_coefficients):\n",
    "    print(f'Coefficient for {feature}: {coefficient:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff1aabc-d22a-4e53-8e10-8d717a9d30fe",
   "metadata": {},
   "source": [
    "## Comparing the performance with other ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964392cb-e486-41a0-88c3-1d291c0e0159",
   "metadata": {},
   "source": [
    "### 10-fold cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2a7820-3098-44b7-a0ff-d9a1f7fc462c",
   "metadata": {},
   "source": [
    "#### Without p50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea49261-3bed-4d1b-a1d3-5160eb7d7745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Select relevant columns\n",
    "selected_features = [\n",
    "    'sofa_past_overall_24hr',\n",
    "    'comorbidity_score_value', 'cbc_hemoglobin', 'bmp_sodium', 'admission_age',\n",
    "    'in_hospital_mortality', 'comorbidity_score_name_Charlson', 'comorbidity_score_name_Elixhauser'\n",
    "]\n",
    "\n",
    "# Create a DataFrame with selected features\n",
    "selected_df = df[selected_features]\n",
    "\n",
    "# Split data\n",
    "X = selected_df.drop('in_hospital_mortality', axis=1)\n",
    "y = selected_df['in_hospital_mortality']\n",
    "\n",
    "# Initialize and train different models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(solver='lbfgs', max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    auc_scores = []  # List to store AUC scores for each validation fold\n",
    "    accuracy_scores = []  # List to store accuracy scores for each validation fold\n",
    "    precision_scores = []  # List to store precision scores for each validation fold\n",
    "    recall_scores = []  # List to store recall scores for each validation fold\n",
    "    f1_scores = []  # List to store F1 scores for each validation fold\n",
    "\n",
    "    # Perform 10-fold cross-validation\n",
    "    k_fold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    for train_idx, test_idx in k_fold.split(X, y):\n",
    "        X_train_fold, X_test_fold = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train_fold, y_test_fold = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        auc_fold = roc_auc_score(y_test_fold, model.predict_proba(X_test_fold)[:, 1])\n",
    "        auc_scores.append(auc_fold)\n",
    "\n",
    "        y_pred = model.predict(X_test_fold)\n",
    "        accuracy_fold = accuracy_score(y_test_fold, y_pred)\n",
    "        accuracy_scores.append(accuracy_fold)\n",
    "        precision_fold = precision_score(y_test_fold, y_pred)\n",
    "        precision_scores.append(precision_fold)\n",
    "        recall_fold = recall_score(y_test_fold, y_pred)\n",
    "        recall_scores.append(recall_fold)\n",
    "        f1_fold = f1_score(y_test_fold, y_pred)\n",
    "        f1_scores.append(f1_fold)\n",
    "\n",
    "    # Calculate 2.5 and 97.5 percentiles to obtain the CI for AUC\n",
    "    alpha = 0.95\n",
    "    lower_auc = np.percentile(auc_scores, 2.5)\n",
    "    upper_auc = np.percentile(auc_scores, 97.5)\n",
    "\n",
    "    results[model_name] = {\n",
    "        'AUC Scores (Validation Folds)': auc_scores,\n",
    "        'AUC 95% CI': (lower_auc, upper_auc),\n",
    "        'Accuracy Scores (Validation Folds)': accuracy_scores,\n",
    "        'Precision Scores (Validation Folds)': precision_scores,\n",
    "        'Recall Scores (Validation Folds)': recall_scores,\n",
    "        'F1 Scores (Validation Folds)': f1_scores\n",
    "    }\n",
    "\n",
    "# Print results in a tabular format with 5 decimal places\n",
    "print(\"Hospital Mortality Prediction without p50: \\n\")\n",
    "print(\"{:<20} {:<15} {:<15} {:<15} {:<15} {:<15}\".format('Model', 'AUC', 'Accuracy', 'Precision', 'Recall', 'F1 Score'))\n",
    "for model_name, metrics in results.items():\n",
    "    print(\"{:<20} {:<15.5f} {:<15.5f} {:<15.5f} {:<15.5f} {:<15.5f}\".format(\n",
    "        model_name,\n",
    "        np.mean(metrics['AUC Scores (Validation Folds)']),\n",
    "        np.mean(metrics['Accuracy Scores (Validation Folds)']),\n",
    "        np.mean(metrics['Precision Scores (Validation Folds)']),\n",
    "        np.mean(metrics['Recall Scores (Validation Folds)']),\n",
    "        np.mean(metrics['F1 Scores (Validation Folds)'])\n",
    "    ))\n",
    "\n",
    "# Add a blank line\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print all the AUC CIs for the models with 5 decimal places\n",
    "for model_name, metrics in results.items():\n",
    "    lower_auc = metrics['AUC 95% CI'][0]\n",
    "    upper_auc = metrics['AUC 95% CI'][1]\n",
    "    print(f'{model_name}: AUC 95% CI ({lower_auc:.5f}, {upper_auc:.5f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89b6e9c-96a1-406a-9408-f59125e561fc",
   "metadata": {},
   "source": [
    "#### With p50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2d8dc6-9afc-4733-b6d9-071d6972714f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Select relevant columns\n",
    "selected_features = ['p50',\n",
    "    'sofa_past_overall_24hr',\n",
    "    'comorbidity_score_value', 'cbc_hemoglobin', 'bmp_sodium', 'admission_age',\n",
    "    'in_hospital_mortality', 'comorbidity_score_name_Charlson', 'comorbidity_score_name_Elixhauser'\n",
    "]\n",
    "\n",
    "# Create a DataFrame with selected features\n",
    "selected_df = df[selected_features]\n",
    "\n",
    "# Split data\n",
    "X = selected_df.drop('in_hospital_mortality', axis=1)\n",
    "y = selected_df['in_hospital_mortality']\n",
    "\n",
    "# Initialize and train different models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(solver='lbfgs', max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    auc_scores = []  # List to store AUC scores for each validation fold\n",
    "    accuracy_scores = []  # List to store accuracy scores for each validation fold\n",
    "    precision_scores = []  # List to store precision scores for each validation fold\n",
    "    recall_scores = []  # List to store recall scores for each validation fold\n",
    "    f1_scores = []  # List to store F1 scores for each validation fold\n",
    "\n",
    "    # Perform 10-fold cross-validation\n",
    "    k_fold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    for train_idx, test_idx in k_fold.split(X, y):\n",
    "        X_train_fold, X_test_fold = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train_fold, y_test_fold = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        auc_fold = roc_auc_score(y_test_fold, model.predict_proba(X_test_fold)[:, 1])\n",
    "        auc_scores.append(auc_fold)\n",
    "\n",
    "        y_pred = model.predict(X_test_fold)\n",
    "        accuracy_fold = accuracy_score(y_test_fold, y_pred)\n",
    "        accuracy_scores.append(accuracy_fold)\n",
    "        precision_fold = precision_score(y_test_fold, y_pred)\n",
    "        precision_scores.append(precision_fold)\n",
    "        recall_fold = recall_score(y_test_fold, y_pred)\n",
    "        recall_scores.append(recall_fold)\n",
    "        f1_fold = f1_score(y_test_fold, y_pred)\n",
    "        f1_scores.append(f1_fold)\n",
    "\n",
    "    # Calculate 2.5 and 97.5 percentiles to obtain the CI for AUC\n",
    "    alpha = 0.95\n",
    "    lower_auc = np.percentile(auc_scores, 2.5)\n",
    "    upper_auc = np.percentile(auc_scores, 97.5)\n",
    "\n",
    "    results[model_name] = {\n",
    "        'AUC Scores (Validation Folds)': auc_scores,\n",
    "        'AUC 95% CI': (lower_auc, upper_auc),\n",
    "        'Accuracy Scores (Validation Folds)': accuracy_scores,\n",
    "        'Precision Scores (Validation Folds)': precision_scores,\n",
    "        'Recall Scores (Validation Folds)': recall_scores,\n",
    "        'F1 Scores (Validation Folds)': f1_scores\n",
    "    }\n",
    "\n",
    "# Print results in a tabular format with 5 decimal places\n",
    "print(\"Hospital Mortality Prediction with p50: \\n\")\n",
    "print(\"{:<20} {:<15} {:<15} {:<15} {:<15} {:<15}\".format('Model', 'AUC', 'Accuracy', 'Precision', 'Recall', 'F1 Score'))\n",
    "for model_name, metrics in results.items():\n",
    "    print(\"{:<20} {:<15.5f} {:<15.5f} {:<15.5f} {:<15.5f} {:<15.5f}\".format(\n",
    "        model_name,\n",
    "        np.mean(metrics['AUC Scores (Validation Folds)']),\n",
    "        np.mean(metrics['Accuracy Scores (Validation Folds)']),\n",
    "        np.mean(metrics['Precision Scores (Validation Folds)']),\n",
    "        np.mean(metrics['Recall Scores (Validation Folds)']),\n",
    "        np.mean(metrics['F1 Scores (Validation Folds)'])\n",
    "    ))\n",
    "\n",
    "# Add a blank line\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print all the AUC CIs for the models with 5 decimal places\n",
    "for model_name, metrics in results.items():\n",
    "    lower_auc = metrics['AUC 95% CI'][0]\n",
    "    upper_auc = metrics['AUC 95% CI'][1]\n",
    "    print(f'{model_name}: AUC 95% CI ({lower_auc:.5f}, {upper_auc:.5f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e187091c-f00a-4346-bdd6-813e41f25022",
   "metadata": {},
   "source": [
    "### Train, Validate with K folds, and test - Comparing AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d8d64d-6b46-4f85-9547-63f133390deb",
   "metadata": {},
   "source": [
    "#### Without p50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d21d8e-c431-4022-b20f-224ed0b8ea0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Select relevant columns\n",
    "selected_features = [\n",
    "    'sofa_past_overall_24hr',\n",
    "    'comorbidity_score_value', 'cbc_hemoglobin', 'bmp_sodium', 'admission_age',\n",
    "    'in_hospital_mortality', 'comorbidity_score_name_Charlson', 'comorbidity_score_name_Elixhauser'\n",
    "]\n",
    "\n",
    "# Create a DataFrame with selected features\n",
    "selected_df = df[selected_features]\n",
    "\n",
    "# Split data into train, validate, and test sets\n",
    "X = selected_df.drop('in_hospital_mortality', axis=1)\n",
    "y = selected_df['in_hospital_mortality']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_validate, X_test, y_validate, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Initialize and train different models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(solver='lbfgs', max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    auc_scores_validate = []  # List to store AUC scores for the validation set\n",
    "    auc_scores_test = []  # List to store AUC scores for the test set\n",
    "    accuracy_scores_validate = []  # List to store accuracy scores for the validation set\n",
    "    accuracy_scores_test = []  # List to store accuracy scores for the test set\n",
    "\n",
    "    k_fold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    for train_idx, val_idx in k_fold.split(X_validate, y_validate):\n",
    "        X_train_fold, X_val_fold = X_validate.iloc[train_idx], X_validate.iloc[val_idx]\n",
    "        y_train_fold, y_val_fold = y_validate.iloc[train_idx], y_validate.iloc[val_idx]\n",
    "\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        # Validation Set\n",
    "        y_pred_val = model.predict(X_val_fold)\n",
    "        auc_val = roc_auc_score(y_val_fold, model.predict_proba(X_val_fold)[:, 1])\n",
    "        auc_scores_validate.append(auc_val)\n",
    "        accuracy_val = accuracy_score(y_val_fold, y_pred_val)\n",
    "        accuracy_scores_validate.append(accuracy_val)\n",
    "\n",
    "    # Test Set\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    auc_test = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "    auc_scores_test.append(auc_test)\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    accuracy_scores_test.append(accuracy_test)\n",
    "\n",
    "    results[model_name] = {\n",
    "        'AUC Score (Validation Set)': np.mean(auc_scores_validate),\n",
    "        'AUC Score (Test Set)': np.mean(auc_scores_test),\n",
    "        'Accuracy (Validation Set)': np.mean(accuracy_scores_validate),\n",
    "        'Accuracy (Test Set)': np.mean(accuracy_scores_test)\n",
    "    }\n",
    "\n",
    "# Print results\n",
    "print(\"Model Performance:\")\n",
    "print(\"{:<20} {:<20} {:<20}\".format('Model', 'Validation Set', 'Test Set'))\n",
    "for model_name, metrics in results.items():\n",
    "    print(\"{:<20} {:<20.5f} {:<20.5f}\".format(\n",
    "        model_name,\n",
    "        metrics['AUC Score (Validation Set)'],\n",
    "        metrics['AUC Score (Test Set)']\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67756347-67b6-4f0f-8c15-99fa819a487d",
   "metadata": {},
   "source": [
    "#### with p50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94af5e37-660e-4bab-836c-fd9445edb165",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Select relevant columns\n",
    "selected_features = ['p50',\n",
    "    'sofa_past_overall_24hr',\n",
    "    'comorbidity_score_value', 'cbc_hemoglobin', 'bmp_sodium', 'admission_age',\n",
    "    'in_hospital_mortality', 'comorbidity_score_name_Charlson', 'comorbidity_score_name_Elixhauser'\n",
    "]\n",
    "\n",
    "# Create a DataFrame with selected features\n",
    "selected_df = df[selected_features]\n",
    "\n",
    "# Split data into train, validate, and test sets\n",
    "X = selected_df.drop('in_hospital_mortality', axis=1)\n",
    "y = selected_df['in_hospital_mortality']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_validate, X_test, y_validate, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Initialize and train different models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(solver='lbfgs', max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    auc_scores_validate = []  # List to store AUC scores for the validation set\n",
    "    auc_scores_test = []  # List to store AUC scores for the test set\n",
    "    accuracy_scores_validate = []  # List to store accuracy scores for the validation set\n",
    "    accuracy_scores_test = []  # List to store accuracy scores for the test set\n",
    "\n",
    "    k_fold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    for train_idx, val_idx in k_fold.split(X_validate, y_validate):\n",
    "        X_train_fold, X_val_fold = X_validate.iloc[train_idx], X_validate.iloc[val_idx]\n",
    "        y_train_fold, y_val_fold = y_validate.iloc[train_idx], y_validate.iloc[val_idx]\n",
    "\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        # Validation Set\n",
    "        y_pred_val = model.predict(X_val_fold)\n",
    "        auc_val = roc_auc_score(y_val_fold, model.predict_proba(X_val_fold)[:, 1])\n",
    "        auc_scores_validate.append(auc_val)\n",
    "        accuracy_val = accuracy_score(y_val_fold, y_pred_val)\n",
    "        accuracy_scores_validate.append(accuracy_val)\n",
    "\n",
    "    # Test Set\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    auc_test = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "    auc_scores_test.append(auc_test)\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    accuracy_scores_test.append(accuracy_test)\n",
    "\n",
    "    results[model_name] = {\n",
    "        'AUC Score (Validation Set)': np.mean(auc_scores_validate),\n",
    "        'AUC Score (Test Set)': np.mean(auc_scores_test),\n",
    "        'Accuracy (Validation Set)': np.mean(accuracy_scores_validate),\n",
    "        'Accuracy (Test Set)': np.mean(accuracy_scores_test)\n",
    "    }\n",
    "\n",
    "# Print results\n",
    "print(\"Model Performance:\")\n",
    "print(\"{:<20} {:<20} {:<20}\".format('Model', 'Validation Set', 'Test Set'))\n",
    "for model_name, metrics in results.items():\n",
    "    print(\"{:<20} {:<20.5f} {:<20.5f}\".format(\n",
    "        model_name,\n",
    "        metrics['AUC Score (Validation Set)'],\n",
    "        metrics['AUC Score (Test Set)']\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f67884-15e5-49b8-8e8d-afc459c50e4a",
   "metadata": {},
   "source": [
    "### Train, Validate with K folds, and test - Comparing AUC, Accuracy, Precision, Recall, F1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c7cd69-38aa-4add-b435-f9e13edfbd6b",
   "metadata": {},
   "source": [
    "#### Without p50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a87742cb-5969-4c56-8e09-785814f5fef1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 16\u001b[0m\n\u001b[1;32m      9\u001b[0m selected_features \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msofa_past_overall_24hr\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomorbidity_score_value\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcbc_hemoglobin\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbmp_sodium\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madmission_age\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min_hospital_mortality\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomorbidity_score_name_Charlson\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomorbidity_score_name_Elixhauser\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     13\u001b[0m ]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Create a DataFrame with selected features\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m selected_df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[selected_features]\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Split data into train, validate, and test sets\u001b[39;00m\n\u001b[1;32m     19\u001b[0m X \u001b[38;5;241m=\u001b[39m selected_df\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124min_hospital_mortality\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Select relevant columns\n",
    "selected_features = [\n",
    "    'sofa_past_overall_24hr',\n",
    "    'comorbidity_score_value', 'cbc_hemoglobin', 'bmp_sodium', 'admission_age',\n",
    "    'in_hospital_mortality', 'comorbidity_score_name_Charlson', 'comorbidity_score_name_Elixhauser'\n",
    "]\n",
    "\n",
    "# Create a DataFrame with selected features\n",
    "selected_df = df[selected_features]\n",
    "\n",
    "# Split data into train, validate, and test sets\n",
    "X = selected_df.drop('in_hospital_mortality', axis=1)\n",
    "y = selected_df['in_hospital_mortality']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_validate, X_test, y_validate, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Initialize and train different models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(solver='lbfgs', max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "results_validate = {}\n",
    "results_test = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    auc_scores_validate = []  # List to store AUC scores for each validation fold\n",
    "    accuracy_scores_validate = []  # List to store accuracy scores for each validation fold\n",
    "    precision_scores_validate = []  # List to store precision scores for each validation fold\n",
    "    recall_scores_validate = []  # List to store recall scores for each validation fold\n",
    "    f1_scores_validate = []  # List to store F1 scores for each validation fold\n",
    "\n",
    "    auc_scores_test = []  # List to store AUC scores for the test set\n",
    "    accuracy_scores_test = []  # List to store accuracy scores for the test set\n",
    "    precision_scores_test = []  # List to store precision scores for the test set\n",
    "    recall_scores_test = []  # List to store recall scores for the test set\n",
    "    f1_scores_test = []  # List to store F1 scores for the test set\n",
    "\n",
    "    # Perform 10-fold cross-validation on the validation set\n",
    "    k_fold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    for train_idx, validate_idx in k_fold.split(X_validate, y_validate):\n",
    "        X_train_fold, X_validate_fold = X_validate.iloc[train_idx], X_validate.iloc[validate_idx]\n",
    "        y_train_fold, y_validate_fold = y_validate.iloc[train_idx], y_validate.iloc[validate_idx]\n",
    "\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        auc_fold_validate = roc_auc_score(y_validate_fold, model.predict_proba(X_validate_fold)[:, 1])\n",
    "        auc_scores_validate.append(auc_fold_validate)\n",
    "\n",
    "        y_pred_validate = model.predict(X_validate_fold)\n",
    "        accuracy_fold_validate = accuracy_score(y_validate_fold, y_pred_validate)\n",
    "        accuracy_scores_validate.append(accuracy_fold_validate)\n",
    "        precision_fold_validate = precision_score(y_validate_fold, y_pred_validate)\n",
    "        precision_scores_validate.append(precision_fold_validate)\n",
    "        recall_fold_validate = recall_score(y_validate_fold, y_pred_validate)\n",
    "        recall_scores_validate.append(recall_fold_validate)\n",
    "        f1_fold_validate = f1_score(y_validate_fold, y_pred_validate)\n",
    "        f1_scores_validate.append(f1_fold_validate)\n",
    "\n",
    "    # Now evaluate on the test set\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    auc_test = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "    auc_scores_test.append(auc_test)\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    accuracy_scores_test.append(accuracy_test)\n",
    "    precision_test = precision_score(y_test, y_pred_test)\n",
    "    precision_scores_test.append(precision_test)\n",
    "    recall_test = recall_score(y_test, y_pred_test)\n",
    "    recall_scores_test.append(recall_test)\n",
    "    f1_test = f1_score(y_test, y_pred_test)\n",
    "    f1_scores_test.append(f1_test)\n",
    "\n",
    "    # Calculate 2.5 and 97.5 percentiles to obtain the CI for AUC on the validation set\n",
    "    alpha = 0.95\n",
    "    lower_auc_validate = np.percentile(auc_scores_validate, 2.5)\n",
    "    upper_auc_validate = np.percentile(auc_scores_validate, 97.5)\n",
    "\n",
    "    results_validate[model_name] = {\n",
    "        'AUC Scores (Validation Folds)': auc_scores_validate,\n",
    "        'AUC 95% CI': (lower_auc_validate, upper_auc_validate),\n",
    "        'Accuracy Scores (Validation Folds)': accuracy_scores_validate,\n",
    "        'Precision Scores (Validation Folds)': precision_scores_validate,\n",
    "        'Recall Scores (Validation Folds)': recall_scores_validate,\n",
    "        'F1 Scores (Validation Folds)': f1_scores_validate\n",
    "    }\n",
    "\n",
    "    # Store the test set metrics\n",
    "    results_test[model_name] = {\n",
    "        'AUC Test Score': np.mean(auc_scores_test),\n",
    "        'Accuracy Test Score': np.mean(accuracy_scores_test),\n",
    "        'Precision Test Score': np.mean(precision_scores_test),\n",
    "        'Recall Test Score': np.mean(recall_scores_test),\n",
    "        'F1 Test Score': np.mean(f1_scores_test)\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Hospital Mortality Prediction without p50: \\n\")\n",
    "# Add a blank line\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print results for the validation set in a tabular format with 5 decimal places\n",
    "print(\"Validation Set Metrics: \\n\")\n",
    "print(\"{:<20} {:<15} {:<15} {:<15} {:<15} {:<15}\".format('Model', 'AUC', 'Accuracy', 'Precision', 'Recall', 'F1 Score'))\n",
    "for model_name, metrics in results_validate.items():\n",
    "    print(\"{:<20} {:<15.5f} {:<15.5f} {:<15.5f} {:<15.5f} {:<15.5f}\".format(\n",
    "        model_name,\n",
    "        np.mean(metrics['AUC Scores (Validation Folds)']),\n",
    "        np.mean(metrics['Accuracy Scores (Validation Folds)']),\n",
    "        np.mean(metrics['Precision Scores (Validation Folds)']),\n",
    "        np.mean(metrics['Recall Scores (Validation Folds)']),\n",
    "        np.mean(metrics['F1 Scores (Validation Folds)'])\n",
    "    ))\n",
    "\n",
    "# Add a blank line\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print all the AUC CIs for the models on the validation set with 5 decimal places\n",
    "for model_name, metrics in results_validate.items():\n",
    "    lower_auc_validate = metrics['AUC 95% CI'][0]\n",
    "    upper_auc_validate = metrics['AUC 95% CI'][1]\n",
    "    print(f'{model_name}: AUC 95% CI (Validation) ({lower_auc_validate:.5f}, {upper_auc_validate:.5f})')\n",
    "\n",
    "# Print results for the test set tabular format with 5 decimal places\n",
    "print(\"\\nTest Set Metrics: \\n\")\n",
    "print(\"{:<20} {:<15} {:<15} {:<15} {:<15} {:<15}\".format('Model', 'AUC', 'Accuracy', 'Precision', 'Recall', 'F1 Score'))\n",
    "for model_name, metrics in results_test.items():\n",
    "    print(\"{:<20} {:<15.5f} {:<15.5f} {:<15.5f} {:<15.5f} {:<15.5f}\".format(\n",
    "        model_name,\n",
    "        metrics['AUC Test Score'],\n",
    "        metrics['Accuracy Test Score'],\n",
    "        metrics['Precision Test Score'],\n",
    "        metrics['Recall Test Score'],\n",
    "        metrics['F1 Test Score']\n",
    "    ))\n",
    "\n",
    "# Add a blank line\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c7b5d1-89de-453d-be0c-e9e9b138233c",
   "metadata": {},
   "source": [
    "#### With p50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d9fd16c1-526e-46fb-b2f8-93d5c0a3939c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hospital Mortality Prediction with p50: \n",
      "\n",
      "\n",
      "\n",
      "Validation Set Metrics: \n",
      "\n",
      "Model                AUC             Accuracy        Precision       Recall          F1 Score       \n",
      "Logistic Regression  0.69381         0.81938         0.52630         0.05703         0.10226        \n",
      "Decision Tree        0.55213         0.71476         0.25400         0.29699         0.27306        \n",
      "Random Forest        0.67829         0.81594         0.47560         0.09980         0.16393        \n",
      "Gradient Boosting    0.69745         0.81894         0.49979         0.09979         0.16570        \n",
      "\n",
      "\n",
      "Logistic Regression: AUC 95% CI (Validation) (0.64773, 0.73001)\n",
      "Decision Tree: AUC 95% CI (Validation) (0.52158, 0.58527)\n",
      "Random Forest: AUC 95% CI (Validation) (0.65245, 0.70999)\n",
      "Gradient Boosting: AUC 95% CI (Validation) (0.66637, 0.71811)\n",
      "\n",
      "Test Set Metrics: \n",
      "\n",
      "Model                AUC             Accuracy        Precision       Recall          F1 Score       \n",
      "Logistic Regression  0.67458         0.81201         0.59418         0.06704         0.12043        \n",
      "Decision Tree        0.54271         0.71023         0.25776         0.27074         0.26408        \n",
      "Random Forest        0.66169         0.80474         0.45772         0.09260         0.15391        \n",
      "Gradient Boosting    0.67915         0.80766         0.49589         0.09215         0.15533        \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Select relevant columns\n",
    "selected_features = ['p50',\n",
    "    'sofa_past_overall_24hr',\n",
    "    'comorbidity_score_value', 'cbc_hemoglobin', 'bmp_sodium', 'admission_age',\n",
    "    'in_hospital_mortality', 'comorbidity_score_name_Charlson', 'comorbidity_score_name_Elixhauser'\n",
    "]\n",
    "\n",
    "# Create a DataFrame with selected features\n",
    "selected_df = df[selected_features]\n",
    "\n",
    "# Split data into train, validate, and test sets\n",
    "X = selected_df.drop('in_hospital_mortality', axis=1)\n",
    "y = selected_df['in_hospital_mortality']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_validate, X_test, y_validate, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Initialize and train different models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(solver='lbfgs', max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "results_validate = {}\n",
    "results_test = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    auc_scores_validate = []  # List to store AUC scores for each validation fold\n",
    "    accuracy_scores_validate = []  # List to store accuracy scores for each validation fold\n",
    "    precision_scores_validate = []  # List to store precision scores for each validation fold\n",
    "    recall_scores_validate = []  # List to store recall scores for each validation fold\n",
    "    f1_scores_validate = []  # List to store F1 scores for each validation fold\n",
    "\n",
    "    auc_scores_test = []  # List to store AUC scores for the test set\n",
    "    accuracy_scores_test = []  # List to store accuracy scores for the test set\n",
    "    precision_scores_test = []  # List to store precision scores for the test set\n",
    "    recall_scores_test = []  # List to store recall scores for the test set\n",
    "    f1_scores_test = []  # List to store F1 scores for the test set\n",
    "\n",
    "    # Perform 10-fold cross-validation on the validation set\n",
    "    k_fold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    for train_idx, validate_idx in k_fold.split(X_validate, y_validate):\n",
    "        X_train_fold, X_validate_fold = X_validate.iloc[train_idx], X_validate.iloc[validate_idx]\n",
    "        y_train_fold, y_validate_fold = y_validate.iloc[train_idx], y_validate.iloc[validate_idx]\n",
    "\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        auc_fold_validate = roc_auc_score(y_validate_fold, model.predict_proba(X_validate_fold)[:, 1])\n",
    "        auc_scores_validate.append(auc_fold_validate)\n",
    "\n",
    "        y_pred_validate = model.predict(X_validate_fold)\n",
    "        accuracy_fold_validate = accuracy_score(y_validate_fold, y_pred_validate)\n",
    "        accuracy_scores_validate.append(accuracy_fold_validate)\n",
    "        precision_fold_validate = precision_score(y_validate_fold, y_pred_validate)\n",
    "        precision_scores_validate.append(precision_fold_validate)\n",
    "        recall_fold_validate = recall_score(y_validate_fold, y_pred_validate)\n",
    "        recall_scores_validate.append(recall_fold_validate)\n",
    "        f1_fold_validate = f1_score(y_validate_fold, y_pred_validate)\n",
    "        f1_scores_validate.append(f1_fold_validate)\n",
    "\n",
    "        # Now evaluate on the test set\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        auc_test = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "        auc_scores_test.append(auc_test)\n",
    "        accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "        accuracy_scores_test.append(accuracy_test)\n",
    "        precision_test = precision_score(y_test, y_pred_test)\n",
    "        precision_scores_test.append(precision_test)\n",
    "        recall_test = recall_score(y_test, y_pred_test)\n",
    "        recall_scores_test.append(recall_test)\n",
    "        f1_test = f1_score(y_test, y_pred_test)\n",
    "        f1_scores_test.append(f1_test)\n",
    "\n",
    "    # Calculate 2.5 and 97.5 percentiles to obtain the CI for AUC on the validation set\n",
    "    alpha = 0.95\n",
    "    lower_auc_validate = np.percentile(auc_scores_validate, 2.5)\n",
    "    upper_auc_validate = np.percentile(auc_scores_validate, 97.5)\n",
    "\n",
    "    results_validate[model_name] = {\n",
    "        'AUC Scores (Validation Folds)': auc_scores_validate,\n",
    "        'AUC 95% CI': (lower_auc_validate, upper_auc_validate),\n",
    "        'Accuracy Scores (Validation Folds)': accuracy_scores_validate,\n",
    "        'Precision Scores (Validation Folds)': precision_scores_validate,\n",
    "        'Recall Scores (Validation Folds)': recall_scores_validate,\n",
    "        'F1 Scores (Validation Folds)': f1_scores_validate\n",
    "    }\n",
    "\n",
    "    # Store the test set metrics\n",
    "    results_test[model_name] = {\n",
    "        'AUC Test Score': np.mean(auc_scores_test),\n",
    "        'Accuracy Test Score': np.mean(accuracy_scores_test),\n",
    "        'Precision Test Score': np.mean(precision_scores_test),\n",
    "        'Recall Test Score': np.mean(recall_scores_test),\n",
    "        'F1 Test Score': np.mean(f1_scores_test)\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "print(\"Hospital Mortality Prediction with p50: \\n\")\n",
    "# Add a blank line\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print results for the validation set in a tabular format with 5 decimal places\n",
    "print(\"Validation Set Metrics: \\n\")\n",
    "print(\"{:<20} {:<15} {:<15} {:<15} {:<15} {:<15}\".format('Model', 'AUC', 'Accuracy', 'Precision', 'Recall', 'F1 Score'))\n",
    "for model_name, metrics in results_validate.items():\n",
    "    print(\"{:<20} {:<15.5f} {:<15.5f} {:<15.5f} {:<15.5f} {:<15.5f}\".format(\n",
    "        model_name,\n",
    "        np.mean(metrics['AUC Scores (Validation Folds)']),\n",
    "        np.mean(metrics['Accuracy Scores (Validation Folds)']),\n",
    "        np.mean(metrics['Precision Scores (Validation Folds)']),\n",
    "        np.mean(metrics['Recall Scores (Validation Folds)']),\n",
    "        np.mean(metrics['F1 Scores (Validation Folds)'])\n",
    "    ))\n",
    "\n",
    "# Add a blank line\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print all the AUC CIs for the models on the validation set with 5 decimal places\n",
    "for model_name, metrics in results_validate.items():\n",
    "    lower_auc_validate = metrics['AUC 95% CI'][0]\n",
    "    upper_auc_validate = metrics['AUC 95% CI'][1]\n",
    "    print(f'{model_name}: AUC 95% CI (Validation) ({lower_auc_validate:.5f}, {upper_auc_validate:.5f})')\n",
    "\n",
    "# Print results for the test set tabular format with 5 decimal places\n",
    "print(\"\\nTest Set Metrics: \\n\")\n",
    "print(\"{:<20} {:<15} {:<15} {:<15} {:<15} {:<15}\".format('Model', 'AUC', 'Accuracy', 'Precision', 'Recall', 'F1 Score'))\n",
    "for model_name, metrics in results_test.items():\n",
    "    print(\"{:<20} {:<15.5f} {:<15.5f} {:<15.5f} {:<15.5f} {:<15.5f}\".format(\n",
    "        model_name,\n",
    "        metrics['AUC Test Score'],\n",
    "        metrics['Accuracy Test Score'],\n",
    "        metrics['Precision Test Score'],\n",
    "        metrics['Recall Test Score'],\n",
    "        metrics['F1 Test Score']\n",
    "    ))\n",
    "\n",
    "# Add a blank line\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1418e198-671a-409c-b196-5a32402ebf24",
   "metadata": {},
   "source": [
    "Out of the 4 models, Gradient Boosting is performing the best overall. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a32793-e2c6-4636-bb20-f9962fc88217",
   "metadata": {},
   "source": [
    "### Next steps: \n",
    "* Optimizing further Grading Boosting to further prove the predictive power of p50\n",
    "    * GridSearchCV\n",
    "* Analyzing feature importance for each model -> provide insights into the model's decision-making process.\n",
    "* \"By incorporating the p50 feature into pre-trained mortality prediction models, we aim to assess whether this addition leads to an improvement in accuracy. \n",
    "  *  OASIS\n",
    "  *  \"Reproducibility in critical care: a mortality prediction case study\" Link: https://proceedings.mlr.press/v68/johnson17a.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5792d147-2b20-48aa-8b62-f686d91ccd61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc511dd3-89ff-43ac-acd3-48ad1ac9f46d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890084e6-a5c7-49fd-a9e8-f4fe159f4a27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
