{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfULIyaT9IqS"
   },
   "source": [
    "# Loading the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zBvi5yFh8a5Z",
    "outputId": "319308af-6273-4bcd-d677-ea3f64d91651"
   },
   "outputs": [],
   "source": [
    "# ! pip install pandas-profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "StnL1Z1p6_H-"
   },
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eAXy6m9Q7BSS",
    "outputId": "8047ec59-5fbd-4351-b30b-45e1c16e5785"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to your CSV file\n",
    "csv_path = '/Users/mac/Desktop/Summer_2023/datathon/pulseox_dataset.csv'\n",
    "\n",
    "# Read the CSV file using Pandas\n",
    "df_initial = pd.read_csv(csv_path, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VAdXLhRr8MYN",
    "outputId": "3a90b059-7dc6-4c91-c61e-01d40531bfba"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_subject_id</th>\n",
       "      <th>unique_hospital_admission_id</th>\n",
       "      <th>unique_icustay_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hospital_admission_id</th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>source_db</th>\n",
       "      <th>hospitalid</th>\n",
       "      <th>numbedscategory</th>\n",
       "      <th>teachingstatus</th>\n",
       "      <th>...</th>\n",
       "      <th>delta_sofa_future_coagulation_24hr</th>\n",
       "      <th>sofa_future_coagulation_24hr</th>\n",
       "      <th>delta_sofa_future_liver_24hr</th>\n",
       "      <th>sofa_future_liver_24hr</th>\n",
       "      <th>delta_sofa_future_cardiovascular_24hr</th>\n",
       "      <th>sofa_future_cardiovascular_24hr</th>\n",
       "      <th>delta_sofa_future_cns_24hr</th>\n",
       "      <th>sofa_future_cns_24hr</th>\n",
       "      <th>delta_sofa_future_renal_24hr</th>\n",
       "      <th>sofa_future_renal_24hr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>002-10050</td>\n",
       "      <td>183274</td>\n",
       "      <td>211144</td>\n",
       "      <td>eicu</td>\n",
       "      <td>71</td>\n",
       "      <td>100 - 249</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1525.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1525.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1525.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1525.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1525.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>002-1007</td>\n",
       "      <td>178462</td>\n",
       "      <td>204935</td>\n",
       "      <td>eicu</td>\n",
       "      <td>71</td>\n",
       "      <td>100 - 249</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>002-10187</td>\n",
       "      <td>150828</td>\n",
       "      <td>169525</td>\n",
       "      <td>eicu</td>\n",
       "      <td>73</td>\n",
       "      <td>&gt;= 500</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>1547.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1547.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1547.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1547.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1547.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>002-10306</td>\n",
       "      <td>198249</td>\n",
       "      <td>230427</td>\n",
       "      <td>eicu</td>\n",
       "      <td>63</td>\n",
       "      <td>100 - 249</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1507.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1507.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1507.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1507.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1507.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>002-10324</td>\n",
       "      <td>188445</td>\n",
       "      <td>217835</td>\n",
       "      <td>eicu</td>\n",
       "      <td>73</td>\n",
       "      <td>&gt;= 500</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>1537.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1537.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1537.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1537.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1537.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49088</th>\n",
       "      <td>44897</td>\n",
       "      <td>49088</td>\n",
       "      <td>49088</td>\n",
       "      <td>19995595</td>\n",
       "      <td>21784060</td>\n",
       "      <td>34670930</td>\n",
       "      <td>mimic_iv</td>\n",
       "      <td>9999</td>\n",
       "      <td>&gt;= 500</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49089</th>\n",
       "      <td>44898</td>\n",
       "      <td>49089</td>\n",
       "      <td>49089</td>\n",
       "      <td>19995780</td>\n",
       "      <td>21942461</td>\n",
       "      <td>36805359</td>\n",
       "      <td>mimic_iv</td>\n",
       "      <td>9999</td>\n",
       "      <td>&gt;= 500</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>1557.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1557.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1557.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1557.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1557.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49090</th>\n",
       "      <td>44899</td>\n",
       "      <td>49090</td>\n",
       "      <td>49090</td>\n",
       "      <td>19997293</td>\n",
       "      <td>28847872</td>\n",
       "      <td>31877557</td>\n",
       "      <td>mimic_iv</td>\n",
       "      <td>9999</td>\n",
       "      <td>&gt;= 500</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>1557.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1557.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1557.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1557.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1557.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49091</th>\n",
       "      <td>44900</td>\n",
       "      <td>49091</td>\n",
       "      <td>49091</td>\n",
       "      <td>19997367</td>\n",
       "      <td>20617667</td>\n",
       "      <td>35616526</td>\n",
       "      <td>mimic_iv</td>\n",
       "      <td>9999</td>\n",
       "      <td>&gt;= 500</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>1557.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1557.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1557.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1557.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1557.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49092</th>\n",
       "      <td>44901</td>\n",
       "      <td>49092</td>\n",
       "      <td>49092</td>\n",
       "      <td>19997752</td>\n",
       "      <td>29452285</td>\n",
       "      <td>34531437</td>\n",
       "      <td>mimic_iv</td>\n",
       "      <td>9999</td>\n",
       "      <td>&gt;= 500</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49093 rows × 142 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       unique_subject_id  unique_hospital_admission_id  unique_icustay_id  \\\n",
       "0                      0                             0                  0   \n",
       "1                      1                             1                  1   \n",
       "2                      2                             2                  2   \n",
       "3                      3                             3                  3   \n",
       "4                      4                             4                  4   \n",
       "...                  ...                           ...                ...   \n",
       "49088              44897                         49088              49088   \n",
       "49089              44898                         49089              49089   \n",
       "49090              44899                         49090              49090   \n",
       "49091              44900                         49091              49091   \n",
       "49092              44901                         49092              49092   \n",
       "\n",
       "      subject_id  hospital_admission_id  icustay_id source_db  hospitalid  \\\n",
       "0      002-10050                 183274      211144      eicu          71   \n",
       "1       002-1007                 178462      204935      eicu          71   \n",
       "2      002-10187                 150828      169525      eicu          73   \n",
       "3      002-10306                 198249      230427      eicu          63   \n",
       "4      002-10324                 188445      217835      eicu          73   \n",
       "...          ...                    ...         ...       ...         ...   \n",
       "49088   19995595               21784060    34670930  mimic_iv        9999   \n",
       "49089   19995780               21942461    36805359  mimic_iv        9999   \n",
       "49090   19997293               28847872    31877557  mimic_iv        9999   \n",
       "49091   19997367               20617667    35616526  mimic_iv        9999   \n",
       "49092   19997752               29452285    34531437  mimic_iv        9999   \n",
       "\n",
       "      numbedscategory  teachingstatus  ... delta_sofa_future_coagulation_24hr  \\\n",
       "0           100 - 249           False  ...                             1525.0   \n",
       "1           100 - 249           False  ...                                NaN   \n",
       "2              >= 500            True  ...                             1547.0   \n",
       "3           100 - 249           False  ...                             1507.0   \n",
       "4              >= 500            True  ...                             1537.0   \n",
       "...               ...             ...  ...                                ...   \n",
       "49088          >= 500            True  ...                             1500.0   \n",
       "49089          >= 500            True  ...                             1557.0   \n",
       "49090          >= 500            True  ...                             1557.0   \n",
       "49091          >= 500            True  ...                             1557.0   \n",
       "49092          >= 500            True  ...                             1559.0   \n",
       "\n",
       "       sofa_future_coagulation_24hr  delta_sofa_future_liver_24hr  \\\n",
       "0                               1.0                        1525.0   \n",
       "1                               NaN                           NaN   \n",
       "2                               0.0                        1547.0   \n",
       "3                               2.0                        1507.0   \n",
       "4                               1.0                        1537.0   \n",
       "...                             ...                           ...   \n",
       "49088                           0.0                        1500.0   \n",
       "49089                           2.0                        1557.0   \n",
       "49090                           0.0                        1557.0   \n",
       "49091                           3.0                        1557.0   \n",
       "49092                           0.0                        1559.0   \n",
       "\n",
       "       sofa_future_liver_24hr  delta_sofa_future_cardiovascular_24hr  \\\n",
       "0                         0.0                                 1525.0   \n",
       "1                         NaN                                    NaN   \n",
       "2                         0.0                                 1547.0   \n",
       "3                         0.0                                 1507.0   \n",
       "4                         0.0                                 1537.0   \n",
       "...                       ...                                    ...   \n",
       "49088                     2.0                                 1500.0   \n",
       "49089                     0.0                                 1557.0   \n",
       "49090                     0.0                                 1557.0   \n",
       "49091                     2.0                                 1557.0   \n",
       "49092                     0.0                                 1559.0   \n",
       "\n",
       "       sofa_future_cardiovascular_24hr delta_sofa_future_cns_24hr  \\\n",
       "0                                  1.0                     1525.0   \n",
       "1                                  NaN                        NaN   \n",
       "2                                  1.0                     1547.0   \n",
       "3                                  1.0                     1507.0   \n",
       "4                                  1.0                     1537.0   \n",
       "...                                ...                        ...   \n",
       "49088                              1.0                     1500.0   \n",
       "49089                              1.0                     1557.0   \n",
       "49090                              1.0                     1557.0   \n",
       "49091                              1.0                     1557.0   \n",
       "49092                              1.0                     1559.0   \n",
       "\n",
       "      sofa_future_cns_24hr delta_sofa_future_renal_24hr sofa_future_renal_24hr  \n",
       "0                      0.0                       1525.0                    0.0  \n",
       "1                      NaN                          NaN                    NaN  \n",
       "2                      0.0                       1547.0                    0.0  \n",
       "3                      0.0                       1507.0                    1.0  \n",
       "4                      2.0                       1537.0                    0.0  \n",
       "...                    ...                          ...                    ...  \n",
       "49088                  0.0                       1500.0                    1.0  \n",
       "49089                  2.0                       1557.0                    0.0  \n",
       "49090                  1.0                       1557.0                    1.0  \n",
       "49091                  1.0                       1557.0                    1.0  \n",
       "49092                  1.0                       1559.0                    0.0  \n",
       "\n",
       "[49093 rows x 142 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49093, 142)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_initial.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gat01yoRL8PN",
    "outputId": "4798c50a-aff2-41b1-b2c2-bc98428a24b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names: ['unique_subject_id', 'unique_hospital_admission_id', 'unique_icustay_id', 'subject_id', 'hospital_admission_id', 'icustay_id', 'source_db', 'hospitalid', 'numbedscategory', 'teachingstatus', 'region', 'admission_age', 'sex_female', 'weight_admission', 'height_admission', 'BMI_admission', 'datetime_hospital_admit', 'datetime_hospital_discharge', 'datetime_icu_admit', 'datetime_icu_discharge', 'los_hospital', 'los_ICU', 'comorbidity_score_name', 'comorbidity_score_value', 'in_hospital_mortality', 'race_ethnicity', 'SaO2_timestamp', 'pH', 'pCO2', 'pO2', 'SaO2', 'SpO2', 'Carboxyhemoglobin', 'Methemoglobin', 'SpO2_timestamp', 'delta_SpO2', 'delta_vitals_heart_rate', 'vitals_heart_rate', 'delta_vitals_resp_rate', 'vitals_resp_rate', 'delta_vitals_mbp_ni', 'vitals_mbp_ni', 'delta_vitals_sbp_ni', 'vitals_sbp_ni', 'delta_vitals_dbp_ni', 'vitals_dbp_ni', 'delta_vitals_mbp_i', 'vitals_mbp_i', 'delta_vitals_sbp_i', 'vitals_sbp_i', 'delta_vitals_dbp_i', 'vitals_dbp_i', 'delta_vitals_tempc', 'vitals_tempc', 'delta_cbc_hemoglobin', 'cbc_hemoglobin', 'delta_cbc_hematocrit', 'cbc_hematocrit', 'delta_cbc_mch', 'cbc_mch', 'delta_cbc_mchc', 'cbc_mchc', 'delta_cbc_mcv', 'cbc_mcv', 'delta_cbc_platelet', 'cbc_platelet', 'delta_cbc_rbc', 'cbc_rbc', 'delta_cbc_rdw', 'cbc_rdw', 'delta_cbc_wbc', 'cbc_wbc', 'delta_coag_fibrinogen', 'coag_fibrinogen', 'delta_coag_inr', 'coag_inr', 'delta_coag_pt', 'coag_pt', 'delta_coag_ptt', 'coag_ptt', 'delta_bmp_sodium', 'bmp_sodium', 'delta_bmp_potassium', 'bmp_potassium', 'delta_bmp_chloride', 'bmp_chloride', 'delta_bmp_bicarbonate', 'bmp_bicarbonate', 'delta_bmp_bun', 'bmp_bun', 'delta_bmp_creatinine', 'bmp_creatinine', 'delta_bmp_glucose', 'bmp_glucose', 'delta_bmp_aniongap', 'bmp_aniongap', 'delta_bmp_calcium', 'bmp_calcium', 'delta_bmp_lactate', 'bmp_lactate', 'delta_hfp_alt', 'hfp_alt', 'delta_hfp_alp', 'hfp_alp', 'delta_hfp_ast', 'hfp_ast', 'delta_hfp_bilirubin_total', 'hfp_bilirubin_total', 'delta_hfp_bilirubin_direct', 'hfp_bilirubin_direct', 'delta_hfp_albumin', 'hfp_albumin', 'delta_others_ck_cpk', 'others_ck_cpk', 'delta_others_ck_mb', 'others_ck_mb', 'delta_others_ld_ldh', 'others_ld_ldh', 'delta_sofa_past_overall_24hr', 'sofa_past_overall_24hr', 'delta_sofa_past_coagulation_24hr', 'sofa_past_coagulation_24hr', 'delta_sofa_past_liver_24hr', 'sofa_past_liver_24hr', 'delta_sofa_past_cardiovascular_24hr', 'sofa_past_cardiovascular_24hr', 'delta_sofa_past_cns_24hr', 'sofa_past_cns_24hr', 'delta_sofa_past_renal_24hr', 'sofa_past_renal_24hr', 'delta_sofa_future_overall_24hr', 'sofa_future_overall_24hr', 'delta_sofa_future_coagulation_24hr', 'sofa_future_coagulation_24hr', 'delta_sofa_future_liver_24hr', 'sofa_future_liver_24hr', 'delta_sofa_future_cardiovascular_24hr', 'sofa_future_cardiovascular_24hr', 'delta_sofa_future_cns_24hr', 'sofa_future_cns_24hr', 'delta_sofa_future_renal_24hr', 'sofa_future_renal_24hr']\n"
     ]
    }
   ],
   "source": [
    "# Assume 'df_initial' is your DataFrame\n",
    "column_names = df_initial.columns.tolist()\n",
    "\n",
    "print(\"Column names:\", column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Keeping columns relevant to our question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to keep\n",
    "  # should we keep the unique ids instead ??? \n",
    "\n",
    "columns_to_keep = [\"subject_id\", \"hospital_admission_id\", \"icustay_id\",\n",
    "    \"admission_age\", \"sex_female\", \"weight_admission\", \"height_admission\",\n",
    "    \"BMI_admission\", \"los_hospital\", \"los_ICU\",\n",
    "    \"comorbidity_score_value\", \"in_hospital_mortality\",\n",
    "    \"race_ethnicity\", \"pH\", \"pO2\", \"SpO2\", \"vitals_tempc\", \"cbc_hemoglobin\",\n",
    "    \"coag_inr\", \"bmp_sodium\", \"bmp_creatinine\", \"bmp_aniongap\", \"hfp_bilirubin_total\", \"hfp_albumin\",\n",
    "    \"sofa_past_overall_24hr\"\n",
    "]\n",
    "\n",
    "# Select only the columns you want to keep\n",
    "df_filtered = df_initial[columns_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Handling Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are missing values in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the entire DataFrame\n",
    "missing_values = df_filtered.isna()  # or df.isnull() \n",
    "\n",
    "# Check if there are any missing values in the entire DataFrame\n",
    "if missing_values.any().any():\n",
    "    print(\"There are missing values in the DataFrame.\")\n",
    "else: \n",
    "    print(\"There are no missing values in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Column  Percentage Missing (%)\n",
      "subject_id                            subject_id                0.000000\n",
      "hospital_admission_id      hospital_admission_id                0.000000\n",
      "icustay_id                            icustay_id                0.000000\n",
      "admission_age                      admission_age                0.004074\n",
      "sex_female                            sex_female                0.000000\n",
      "weight_admission                weight_admission                2.248793\n",
      "height_admission                height_admission                2.615444\n",
      "BMI_admission                      BMI_admission                4.043346\n",
      "los_hospital                        los_hospital                0.000000\n",
      "los_ICU                                  los_ICU                0.000000\n",
      "comorbidity_score_value  comorbidity_score_value                0.004074\n",
      "in_hospital_mortality      in_hospital_mortality                0.822928\n",
      "race_ethnicity                    race_ethnicity                0.000000\n",
      "pH                                            pH                0.000000\n",
      "pO2                                          pO2                0.000000\n",
      "SpO2                                        SpO2                0.000000\n",
      "vitals_tempc                        vitals_tempc               16.212087\n",
      "cbc_hemoglobin                    cbc_hemoglobin               13.843114\n",
      "coag_inr                                coag_inr               34.703522\n",
      "bmp_sodium                            bmp_sodium               13.319618\n",
      "bmp_creatinine                    bmp_creatinine               15.880064\n",
      "bmp_aniongap                        bmp_aniongap               28.026399\n",
      "hfp_bilirubin_total          hfp_bilirubin_total               38.899639\n",
      "hfp_albumin                          hfp_albumin               35.992911\n",
      "sofa_past_overall_24hr    sofa_past_overall_24hr               22.361640\n",
      "Total Percentage Missing in DataFrame: 9.16%\n"
     ]
    }
   ],
   "source": [
    "# Count the number of missing values per column\n",
    "missing_values_count = df_filtered.isna().sum()\n",
    "\n",
    "# Calculate the total number of cells in the DataFrame\n",
    "total_cells = df_filtered.size\n",
    "\n",
    "# Calculate the total number of missing values in the entire DataFrame\n",
    "total_missing_values = missing_values_count.sum()\n",
    "\n",
    "# Calculate the total percentage of missing values in the entire DataFrame\n",
    "total_percentage_missing = (total_missing_values / total_cells) * 100\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "missing_data_summary = pd.DataFrame({\n",
    "    'Column': df_filtered.columns,\n",
    "    'Percentage Missing (%)': (missing_values_count / len(df_filtered)) * 100\n",
    "})\n",
    "\n",
    "# Print the missing data summary\n",
    "print(missing_data_summary)\n",
    "\n",
    "# Print the total percentage of missing values in the entire DataFrame\n",
    "print(\"Total Percentage Missing in DataFrame: {:.2f}%\".format(total_percentage_missing))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of rows with at least one missing value: 74.89%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the percentage of rows (patients) with at least one missing value\n",
    "percentage_rows_with_missing = (df_filtered.isnull().any(axis=1).sum() / len(df_filtered)) * 100\n",
    "\n",
    "# Print the percentage of rows with at least one missing value\n",
    "print(\"Percentage of rows with at least one missing value: {:.2f}%\".format(percentage_rows_with_missing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation of missing values using regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Encoding\n",
    "Variable encoding, also known as feature encoding or categorical encoding, is a fundamental preprocessing step in machine learning and data analysis. Its goal is to convert categorical variables (features) into a numerical format that machine learning algorithms can work with effectively. Categorical variables are those that represent categories or labels rather than numerical quantities. Encoding categorical variables is essential because many machine learning algorithms require numerical input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with non-numeric values:\n",
      "Index(['subject_id', 'race_ethnicity'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Filter columns with non-numeric data types\n",
    "non_numeric_columns = df_imputed.select_dtypes(exclude=['int', 'float']).columns\n",
    "\n",
    "print(\"Columns with non-numeric values:\")\n",
    "print(non_numeric_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame containing only the desired columns\n",
    "non_numeric_columns_df = df_imputed[non_numeric_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>race_ethnicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002-10050</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002-1007</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002-10187</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002-10306</td>\n",
       "      <td>Asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002-10324</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject_id race_ethnicity\n",
       "0  002-10050          White\n",
       "1   002-1007          White\n",
       "2  002-10187          White\n",
       "3  002-10306          Asian\n",
       "4  002-10324          White"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_numeric_columns_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.B: This function converts a DataFrame into Markdown format, which is suitable for rendering as a table in various environments like Jupyter Notebook or Markdown documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in subject_id:\n",
      "['002-10050' '002-1007' '002-10187' ... '19997293' '19997367' '19997752']\n",
      "\n",
      "Unique values in race_ethnicity:\n",
      "['White' 'Asian' 'Black' 'Unknown' 'American Indian / Alaska Native'\n",
      " 'Hispanic OR Latino' 'Native Hawaiian / Pacific Islander'\n",
      " 'More Than One Race']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of columns to check\n",
    "columns_to_check = ['subject_id', 'race_ethnicity']\n",
    "\n",
    "# Get unique values for each column\n",
    "for column in columns_to_check:\n",
    "    unique_values = df_imputed[column].unique()\n",
    "    print(f\"Unique values in {column}:\")\n",
    "    print(unique_values)\n",
    "    print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-hot encoding for 'race_ethnicity'\n",
    "df_encoded = pd.get_dummies(df_imputed, columns=['race_ethnicity'], prefix=['race'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# Perform label encoding for 'subject_id'\n",
    "label_encoder = LabelEncoder()\n",
    "df_imputed['subject_id_encoded'] = label_encoder.fit_transform(df_imputed['subject_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names: ['subject_id', 'hospital_admission_id', 'icustay_id', 'admission_age', 'sex_female', 'weight_admission', 'height_admission', 'BMI_admission', 'los_hospital', 'los_ICU', 'comorbidity_score_value', 'in_hospital_mortality', 'race_ethnicity', 'pH', 'pO2', 'SpO2', 'vitals_tempc', 'cbc_hemoglobin', 'coag_inr', 'bmp_sodium', 'bmp_creatinine', 'bmp_aniongap', 'hfp_bilirubin_total', 'hfp_albumin', 'sofa_past_overall_24hr', 'subject_id_encoded']\n"
     ]
    }
   ],
   "source": [
    "# Assume 'df_initial' is your DataFrame\n",
    "column_names = df_imputed.columns.tolist()\n",
    "\n",
    "print(\"Column names:\", column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing p50 and adding it to the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is called \"df\" and has columns \"pO2\" and \"SpO2\"\n",
    "df['p50'] = ((100 * (df['pO2']**3) / df['SpO2']) - (df['pO2']**3))**(1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Define the range of interest\n",
    "lower_limit = 0  # Replace with your lower limit\n",
    "upper_limit = 10  # Replace with your upper limit\n",
    "\n",
    "# Filter the DataFrame to include only values within the range\n",
    "filtered_df = df[(df['p50'] >= lower_limit) & (df['p50'] <= upper_limit)]\n",
    "\n",
    "# Count instances of each unique value within the range\n",
    "value_counts = filtered_df['p50'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of unique values within the specified range:\n",
      "0.000000    17851\n",
      "0.000488       31\n",
      "0.000775       24\n",
      "0.000977       15\n",
      "0.000388        7\n",
      "0.001953        7\n",
      "0.000615        6\n",
      "0.001550        5\n",
      "9.295157        4\n",
      "0.001230        4\n",
      "8.646658        3\n",
      "9.078990        3\n",
      "8.862824        3\n",
      "8.430491        2\n",
      "9.943656        2\n",
      "8.214325        2\n",
      "9.727490        2\n",
      "0.000308        2\n",
      "0.003100        1\n",
      "0.002461        1\n",
      "4.971828        1\n",
      "9.338390        1\n",
      "7.998158        1\n",
      "8.906057        1\n",
      "9.662640        1\n",
      "9.100607        1\n",
      "7.846842        1\n",
      "3.799976        1\n",
      "9.468090        1\n",
      "9.511323        1\n",
      "7.349659        1\n",
      "9.564656        1\n",
      "Name: p50, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Count of unique values within the specified range:\")\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        26.994894\n",
       "1        43.471717\n",
       "2        31.547938\n",
       "3         0.000000\n",
       "4        57.128729\n",
       "           ...    \n",
       "49088    32.603787\n",
       "49089    22.187561\n",
       "49090    26.234485\n",
       "49091    23.778308\n",
       "49092     0.000000\n",
       "Name: p50, Length: 49093, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['p50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming your DataFrame is called \"your_data\" and has a column \"p50\"\n",
    "plt.hist(df['p50'], bins=10, color='blue', alpha=0.7)\n",
    "plt.title('Histogram of p50')\n",
    "plt.xlabel('p50')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exlusion groups based on non physiologically values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p50 \n",
    "\n",
    "# Numbers in the range (<10,>50) are not physiologically possible \n",
    "# Primary outcome so all values should be whithin the range \n",
    "\n",
    "sample_df_new = df[(df['p50'] > 10) & (df['p50'] < 50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names: ['subject_id', 'hospital_admission_id', 'icustay_id', 'admission_age', 'sex_female', 'weight_admission', 'height_admission', 'BMI_admission', 'los_hospital', 'los_ICU', 'comorbidity_score_value', 'in_hospital_mortality', 'race_ethnicity', 'pH', 'pO2', 'SpO2', 'vitals_tempc', 'cbc_hemoglobin', 'coag_inr', 'bmp_sodium', 'bmp_creatinine', 'bmp_aniongap', 'hfp_bilirubin_total', 'hfp_albumin', 'sofa_past_overall_24hr', 'subject_id_encoded', 'p50']\n"
     ]
    }
   ],
   "source": [
    "column_names_final = sample_df_new.columns.tolist()\n",
    "\n",
    "print(\"Column names:\", column_names_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sw/5f53r1m13rq2jww8lqgbks700000gn/T/ipykernel_1201/3667339608.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sample_df_new['pH'] = sample_df_new[sample_df_new['pH'] <= 7.81]['pH']\n"
     ]
    }
   ],
   "source": [
    "## for ph \n",
    "\n",
    "# Assuming your DataFrame is called \"your_data\" and has a column \"ph\"\n",
    "sample_df_new['pH'] = sample_df_new[sample_df_new['pH'] <= 7.81]['pH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sw/5f53r1m13rq2jww8lqgbks700000gn/T/ipykernel_1201/365939063.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sample_df_new['cbc_hemoglobin'] = sample_df_new[sample_df_new['cbc_hemoglobin'] <= 20]['cbc_hemoglobin']\n"
     ]
    }
   ],
   "source": [
    "## for cbc_hemoglobin\n",
    "sample_df_new['cbc_hemoglobin'] = sample_df_new[sample_df_new['cbc_hemoglobin'] <= 20]['cbc_hemoglobin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sw/5f53r1m13rq2jww8lqgbks700000gn/T/ipykernel_1201/2112235615.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sample_df_new['BMI_admission'] = sample_df_new[sample_df_new['BMI_admission'] <= 100]['BMI_admission']\n"
     ]
    }
   ],
   "source": [
    "## BMI_admission\n",
    "sample_df_new['BMI_admission'] = sample_df_new[sample_df_new['BMI_admission'] <= 100]['BMI_admission']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_9tdLgT8HNT"
   },
   "source": [
    "### Profile Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EYxGghVh8J2h"
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import pandas_profiling  # Import the pandas_profiling library\n",
    "# from pandas_profiling import ProfileReport\n",
    "\n",
    "# # sample_df = df_cleaned_fromMissing.sample(frac=0.1)  # Use 50% of the data for profiling\n",
    "\n",
    "# # Generate a profile report for the DataFrame\n",
    "# # profile = pandas_profiling.ProfileReport(sample_df, pool_size=4) \n",
    "# profile = pandas_profiling.ProfileReport(sample_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.B: Very computationally heavy. Thus we are: \n",
    "* Only using a percentage of the data for profiling\n",
    "* Parallel Processing: If your system supports it, you can enable parallel processing using the pool_size parameter. This can help distribute computations across multiple CPU cores.\n",
    "* Turn Off Specific Analyses: The pandas_profiling.ProfileReport() function has several parameters that allow you to customize the analyses performed. For example, you can turn off correlation computations or histogram calculations if they are not essential for your analysis.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Reason to Remove Outliers: Impact on Clustering:** Outliers can significantly affect the results of clustering algorithms like k-means. Clusters might be pulled or stretched due to the presence of outliers, leading to suboptimal results.\n",
    "- **Reason to Keep Outliers: Algorithm Robustness:** Some clustering algorithms, like hierarchical clustering or DBSCAN, are more robust to the presence of outliers. They might naturally form separate clusters or noise groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimentionality reduction\n",
    "Performing dimensionality reduction before clustering might not be the best approach, as our primary goal is  to understand the characteristics and differences among clusters based on certain features (like gender),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normasation and Standarization: \n",
    "If needed, normalize or standardize your data to ensure that features with different scales don't disproportionately influence the clustering process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # IF NORMALISATION IS NEEDED  \n",
    "# import pandas as pd\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # Select columns to standardize\n",
    "# # columns_to_standardize = ['valence', 'speechiness', 'loudness', 'liveness' , 'instrumentalness', 'energy', 'duration_ms', 'danceability', 'acousticness', 'popularity', 'instance_id']\n",
    "\n",
    "# # Create a StandardScaler object\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # Fit the scaler to the selected columns\n",
    "# scaler.fit(df_imputed)\n",
    "\n",
    "# # Transform the selected columns\n",
    "# df_imputed = scaler.transform(df_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the Number of Clusters (K)\n",
    "\n",
    "- The choice of K (number of clusters) is crucial. There are several methods to help you determine an optimal K, such as the elbow method, silhouette score, or gap statistic. These methods can help you decide on an appropriate number of clusters based on your data.\n",
    "    \n",
    "Working with unsupervised clustering to get the clusters from the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K means "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elbow Method\n",
    "\n",
    "The elbow method is a heuristic technique used to determine the optimal number of clusters in a clustering algorithm, such as k-means. It is called the \"elbow method\" because when the number of clusters increases, the reduction in within-cluster sum of squares (inertia) tends to form an \"elbow\" shape on a plot. The point where the reduction starts to slow down represents a reasonable estimate of the optimal number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "\n",
    "# List to store the within-cluster sum of squares (inertia) for different k values\n",
    "inertia_values = []\n",
    "\n",
    "# Range of k values to test\n",
    "k_range = range(1, 11)\n",
    "\n",
    "# Calculate inertia for each k value\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(df_imputed)\n",
    "    inertia_values.append(kmeans.inertia_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the elbow curve to visualize the inertia values for different k values. The \"elbow\" point in the plot represents a point of diminishing returns, indicating the optimal number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the elbow curve\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(k_range, inertia_values, marker='o')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your plotted graph, look for the point where the inertia starts decreasing more slowly after an initial steep drop. This point is usually considered the \"elbow\" and represents a good choice for the number of clusters.\n",
    "\n",
    "Keep in mind that sometimes the elbow might not be very clear, especially in complex datasets. In such cases, you might need to make a subjective decision based on the trade-off between simplicity (fewer clusters) and capturing meaningful structure in your data (more clusters).\n",
    "\n",
    "Once you've identified the point, the corresponding value of 'k' is a reasonable choice for the number of clusters in your KMeans clustering analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Assuming you've already determined that 2 is the optimal number of clusters\n",
    "num_clusters = 2\n",
    "\n",
    "# Create a KMeans model with the chosen number of clusters\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "kmeans.fit(df_imputed)  # Fit the model\n",
    "\n",
    "# Get the cluster assignments for each data point\n",
    "cluster_labels = kmeans.labels_\n",
    "\n",
    "# Visualize the clusters and data points\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot data points with different colors for each cluster\n",
    "for cluster_id in range(num_clusters):\n",
    "    plt.scatter(\n",
    "        df_imputed['SpO2'][cluster_labels == cluster_id],  # Replace with your desired feature 1 column\n",
    "        df_imputed['pO2'][cluster_labels == cluster_id],  # Replace with your desired feature 2 column\n",
    "        label=f'Cluster {cluster_id}'\n",
    "    )\n",
    "\n",
    "plt.xlabel('SpO2')  # Replace with your desired x-axis label\n",
    "plt.ylabel('pO2')  # Replace with your desired y-axis label\n",
    "plt.title('Cluster Visualization')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "# Create a grid of points along the line formed by 'SpO2' and 'pO2'\n",
    "num_points = 100\n",
    "min_SpO2 = df_imputed['SpO2'].min()\n",
    "max_SpO2 = df_imputed['SpO2'].max()\n",
    "min_pO2 = df_imputed['pO2'].min()\n",
    "max_pO2 = df_imputed['pO2'].max()\n",
    "\n",
    "grid_SpO2, grid_pO2 = np.meshgrid(\n",
    "    np.linspace(min_SpO2, max_SpO2, num_points),\n",
    "    np.linspace(min_pO2, max_pO2, num_points)\n",
    ")\n",
    "\n",
    "# Interpolate 'pH' values for the grid points\n",
    "grid_pH = griddata(\n",
    "    (df_imputed['SpO2'], df_imputed['pO2']),\n",
    "    df_imputed['pH'],\n",
    "    (grid_SpO2, grid_pO2),\n",
    "    method='cubic'\n",
    ")\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot the interpolated pH values as a contour plot\n",
    "contour = plt.contourf(grid_SpO2, grid_pO2, grid_pH, levels=20, cmap='viridis')\n",
    "plt.colorbar(contour, label='pH')\n",
    "\n",
    "# Scatter plot of the actual data points\n",
    "plt.scatter(df_imputed['SpO2'], df_imputed['pO2'], c=df_imputed['pH'], cmap='viridis', alpha=0.7)\n",
    "\n",
    "plt.xlabel('SpO2')\n",
    "plt.ylabel('pO2')\n",
    "plt.title('pH Variation Along SpO2 and pO2 Line')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Replace 'variable' with the actual column name of the variable\n",
    "variable_data = df_imputed['pH']\n",
    "\n",
    "mean_value = variable_data.mean()\n",
    "median_value = variable_data.median()\n",
    "\n",
    "print(mean_value)\n",
    "print(median_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K means in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the bins for categorizing p50 values\n",
    "p50_bins = [0, 22, 30, np.inf]\n",
    "p50_labels = ['p50 < 22', '22 <= p50 <= 30', 'p50 > 30']\n",
    "\n",
    "# Categorize p50 values based on defined bins\n",
    "df_imputed['p50_category'] = pd.cut(df_imputed['p50'], bins=p50_bins, labels=p50_labels)\n",
    "\n",
    "# Select relevant features for visualization\n",
    "relevant_features = ['cbc_hemoglobin', 'pCO2', 'pH', 'p50_category']\n",
    "\n",
    "# Prepare data using relevant features\n",
    "data_for_plot = df_imputed[relevant_features]\n",
    "\n",
    "# Create pair plot with color-coded categories\n",
    "sns.pairplot(data_for_plot, hue='p50_category', diag_kind='kde')\n",
    "plt.suptitle('Pair Plot with Categorization of p50')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K means in 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get values in the 'p50' column for the range '22 <= p50 <= 30'\n",
    "p50_range_values = df_imputed[(df_imputed['p50'] >= 22) & (df_imputed['p50'] <= 30)]['p50']\n",
    "\n",
    "if not p50_range_values.empty:\n",
    "    print(\"Values in the '22 <= p50 <= 30' range:\")\n",
    "    print(p50_range_values)\n",
    "else:\n",
    "    print(\"There are no values in the '22 <= p50 <= 30' range.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relating to Regions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Category features\n",
    "categories = ['Midwest', 'South', 'West', 'Northeast']\n",
    "\n",
    "\n",
    "# Select relevant features for visualization\n",
    "relevant_features = ['p50', 'pCO2', 'pH']\n",
    "\n",
    "# Prepare data using relevant features\n",
    "X = df_imputed[relevant_features]\n",
    "\n",
    "# Perform KMeans clustering\n",
    "kmeans = KMeans(n_clusters=len(categories))\n",
    "cluster_labels = kmeans.fit_predict(X)\n",
    "\n",
    "# Create a figure and axis for the plot\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Assign colors to categories\n",
    "color_map = plt.cm.get_cmap('tab10', len(categories))\n",
    "\n",
    "# Plot the data points with color coding based on categories\n",
    "for i, category in enumerate(categories):\n",
    "    indices = np.where(cluster_labels == i)[0]\n",
    "    ax.scatter(X.iloc[indices, 0], X.iloc[indices, 1], X.iloc[indices, 2], c=color_map(i), label=category)\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel(relevant_features[0])\n",
    "ax.set_ylabel(relevant_features[1])\n",
    "ax.set_zlabel(relevant_features[2])\n",
    "ax.set_title('3D Scatter Plot of Data Points with KMeans Clustering by p50 Categories')\n",
    "\n",
    "# Set pH axis limits\n",
    "ax.set_zlim(0, 10)  # Adjust the limits as needed\n",
    "\n",
    "# Add legend\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Category features\n",
    "categories = ['Midwest', 'South', 'West', 'Northeast']\n",
    "\n",
    "# Select relevant features for visualization\n",
    "relevant_features = ['p50', 'pCO2', 'pH']\n",
    "# relevant_features = ['SpO2', 'pO2', 'pH']\n",
    "\n",
    "\n",
    "# Prepare data using relevant features\n",
    "X = df_imputed[relevant_features]\n",
    "\n",
    "# Perform KMeans clustering\n",
    "kmeans = KMeans(n_clusters=len(categories))\n",
    "cluster_labels = kmeans.fit_predict(X)\n",
    "\n",
    "# Create a figure and axis for the plot\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Assign colors to categories\n",
    "color_map = plt.cm.get_cmap('tab10', len(categories))\n",
    "\n",
    "# Plot the data points with color coding based on categories\n",
    "for i, category in enumerate(categories):\n",
    "    indices = np.where(cluster_labels == i)[0]\n",
    "    ax.scatter(X.iloc[indices, 0], X.iloc[indices, 1], X.iloc[indices, 2], c=color_map(i), label=category)\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel(relevant_features[0])\n",
    "ax.set_ylabel(relevant_features[1])\n",
    "ax.set_zlabel(relevant_features[2])\n",
    "ax.set_title('3D Scatter Plot of Data Points with KMeans Clustering by p50 Categories')\n",
    "\n",
    "# Set pH axis limits\n",
    "ax.set_zlim(0, 10)  # Adjust the limits as needed\n",
    "\n",
    "# Add legend\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relating to ranges of p50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# categorise p50 -> <22 , 22-30, 30> \n",
    "# Define the bins for categorizing p50 values\n",
    "p50_bins = [0, 22, 30, np.inf]\n",
    "p50_labels = ['p50 < 22', '22 <= p50 <= 30', 'p50 > 30']\n",
    "\n",
    "# Select relevant features for visualization\n",
    "# relevant_features = ['SpO2', 'pO2', 'pH']\n",
    "# p50 -> dependent variable \n",
    "# cbc_hemoglobin, pH -> independent\n",
    "relevant_features = ['cbc_hemoglobin', 'pCO2', 'pH']\n",
    "\n",
    "# Prepare data using regions and relevant features\n",
    "X = df_imputed[relevant_features]\n",
    "\n",
    "# Perform KMeans clustering\n",
    "kmeans = KMeans(n_clusters=len(p50_labels))\n",
    "cluster_labels = kmeans.fit_predict(X)\n",
    "\n",
    "# Create a figure and axis for the plot\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Assign colors to regions with transparency (alpha value)\n",
    "color_map = plt.cm.get_cmap('tab10', len(p50_labels))\n",
    "\n",
    "# Plot the data points with color coding based on regions and transparency\n",
    "for i, p50_category in enumerate(p50_labels):\n",
    "    indices = np.where(cluster_labels == i)[0]\n",
    "    ax.scatter(X.iloc[indices, 0], X.iloc[indices, 1], X.iloc[indices, 2], c=color_map(i, alpha=0.5), label=p50_category)\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel(relevant_features[0])\n",
    "ax.set_ylabel(relevant_features[1])\n",
    "ax.set_zlabel(relevant_features[2])\n",
    "ax.set_title('3D Scatter Plot of Data Points with KMeans Clustering by p50 Categories')\n",
    "\n",
    "# Set pH axis limits\n",
    "# ax.set_xlim(0, 100)  # Adjust the limits as needed\n",
    "ax.set_zlim(0, 10)  # Adjust the limits as needed\n",
    "\n",
    "# Add legend\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# categorise p50 -> <22 , 22-30, 30> \n",
    "# Define the bins for categorizing p50 values\n",
    "p50_bins = [0, 22, 30, np.inf]\n",
    "p50_labels = ['p50 < 22', '22 <= p50 <= 30', 'p50 > 30']\n",
    "\n",
    "# Select relevant features for visualization\n",
    "relevant_features = ['vitals_tempc', 'pCO2', 'pH']\n",
    "\n",
    "# Prepare data using regions and relevant features\n",
    "X = df_imputed[relevant_features]\n",
    "\n",
    "# Perform KMeans clustering\n",
    "kmeans = KMeans(n_clusters=len(p50_labels))\n",
    "cluster_labels = kmeans.fit_predict(X)\n",
    "\n",
    "# Create a figure and axis for the plot\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Assign colors to regions with varying transparency (alpha values)\n",
    "color_map = plt.cm.get_cmap('tab10', len(p50_labels))\n",
    "\n",
    "# Vary transparency based on the index\n",
    "for i, p50_category in enumerate(p50_labels):\n",
    "    indices = np.where(cluster_labels == i)[0]\n",
    "    alpha_value = (i + 1) / len(p50_labels)  # Vary transparency based on index\n",
    "    ax.scatter(X.iloc[indices, 0], X.iloc[indices, 1], X.iloc[indices, 2], c=color_map(i, alpha=alpha_value), label=p50_category)\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel(relevant_features[0])\n",
    "ax.set_ylabel(relevant_features[1])\n",
    "ax.set_zlabel(relevant_features[2])\n",
    "ax.set_title('3D Scatter Plot of Data Points with KMeans Clustering by p50 Categories')\n",
    "\n",
    "# Set pH axis limits\n",
    "# ax.set_xlim(0, 100)  # Adjust the limits as needed\n",
    "ax.set_zlim(0, 10)  # Adjust the limits as needed\n",
    "\n",
    "# Add legend\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relating to Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Category features\n",
    "categories = ['White', 'Asian', 'American Indian / Alaska Native', 'Hispanic OR Latino', 'Black', 'Native Hawaiian / Pacific Islander']\n",
    "\n",
    "# Select relevant features for visualization\n",
    "relevant_features = ['p50', 'pCO2', 'pH']\n",
    "\n",
    "# Prepare data using relevant features\n",
    "X = df_imputed[relevant_features]\n",
    "\n",
    "# Perform KMeans clustering\n",
    "kmeans = KMeans(n_clusters=len(categories))\n",
    "cluster_labels = kmeans.fit_predict(X)\n",
    "\n",
    "# Create a figure and axis for the plot\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Assign colors to categories\n",
    "color_map = plt.cm.get_cmap('tab10', len(categories))\n",
    "\n",
    "# Plot the data points with color coding based on categories\n",
    "for i, category in enumerate(categories):\n",
    "    indices = np.where(cluster_labels == i)[0]\n",
    "    ax.scatter(X.iloc[indices, 0], X.iloc[indices, 1], X.iloc[indices, 2], c=color_map(i), label=category)\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel(relevant_features[0])\n",
    "ax.set_ylabel(relevant_features[1])\n",
    "ax.set_zlabel(relevant_features[2])\n",
    "ax.set_title('3D Scatter Plot of Data Points with KMeans Clustering by p50 Categories')\n",
    "\n",
    "# Set pH axis limits\n",
    "ax.set_zlim(0, 10)  # Adjust the limits as needed\n",
    "\n",
    "# Add legend\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relating to Sex "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Select relevant features for visualization\n",
    "relevant_features = ['p50', 'pCO2', 'pH']\n",
    "\n",
    "# Prepare data using relevant features\n",
    "X = df_imputed[relevant_features]\n",
    "\n",
    "# Create a figure and axis for the plot\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Assign colors based on 'sex_female' column\n",
    "colors = np.where(df_imputed['sex_female'] == 1, 'r', 'b')  # Red for female, blue for not female\n",
    "\n",
    "# Plot the data points with color coding based on 'sex_female' column\n",
    "scatter = ax.scatter(X[relevant_features[0]], X[relevant_features[1]], X[relevant_features[2]], c=colors)\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel(relevant_features[0])\n",
    "ax.set_ylabel(relevant_features[1])\n",
    "ax.set_zlabel(relevant_features[2])\n",
    "ax.set_title('3D Scatter Plot with Color Coding for sex_female')\n",
    "\n",
    "# Set pH axis limits\n",
    "ax.set_zlim(0, 10)  # Adjust the limits as needed\n",
    "\n",
    "# Add legend\n",
    "ax.legend(*scatter.legend_elements(), title='sex_female')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN\n",
    "We can perform clustering, including DBSCAN, without converting categorical variables into numerical ones. DBSCAN (Density-Based Spatial Clustering of Applications with Noise) is a density-based clustering algorithm that can work directly with categorical variables without requiring explicit numerical encoding.\n",
    "Background: DBSCAN operates by defining clusters as dense regions of data points separated by areas of lower density. This makes it suitable for discovering clusters of arbitrary shapes and handling noise.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Select relevant features for visualization\n",
    "relevant_features = ['pCO2', 'p50', 'pH']\n",
    "\n",
    "# Prepare data using relevant features\n",
    "X = df_imputed[relevant_features]\n",
    "\n",
    "# Scale the features for DBSCAN\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Perform DBSCAN clustering\n",
    "eps = 0.5\n",
    "min_samples = 5\n",
    "dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "cluster_labels = dbscan.fit_predict(X_scaled)\n",
    "\n",
    "# Create a figure and axis for the plot\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot the data points with color coding based on clusters\n",
    "unique_labels = np.unique(cluster_labels)\n",
    "color_map = plt.cm.get_cmap('tab20', len(unique_labels))\n",
    "\n",
    "for label in unique_labels:\n",
    "    if label == -1:  # Outliers\n",
    "        indices = np.where(cluster_labels == label)[0]\n",
    "        ax.scatter(X_scaled[indices, 0], X_scaled[indices, 1], X_scaled[indices, 2], c='gray', label='Outliers', alpha=0.2)\n",
    "    else:\n",
    "        indices = np.where(cluster_labels == label)[0]\n",
    "        ax.scatter(X_scaled[indices, 0], X_scaled[indices, 1], X_scaled[indices, 2], c=color_map(label), label=f'Cluster {label}', alpha=0.5)\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel(relevant_features[0])\n",
    "ax.set_ylabel(relevant_features[1])\n",
    "ax.set_zlabel(relevant_features[2])\n",
    "ax.set_title('3D Scatter Plot of Data Points with DBSCAN Clustering')\n",
    "\n",
    "# Add legend\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "# from sklearn.metrics import silhouette_score\n",
    "# from scipy.spatial.distance import cdist\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.manifold import TSNE\n",
    "\n",
    "# # Generate 2D embedding using t-SNE with perplexity=20\n",
    "# tsne = TSNE(n_components=2, perplexity=20, random_state=42)\n",
    "# embedding = tsne.fit_transform(df_imputed)\n",
    "\n",
    "# # Determine optimal  number of clusters using Silhouette method\n",
    "# sil_scores = []\n",
    "# for k in range(2, 11):\n",
    "#     kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "#     cluster_labels = kmeans.fit_predict(embedding)\n",
    "#     sil_score = silhouette_score(embedding, cluster_labels)\n",
    "#     sil_scores.append(sil_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import DBSCAN\n",
    "# import numpy as np\n",
    "\n",
    "# optimal_k = np.argmax(sil_scores) + 2\n",
    "\n",
    "# print('Optimal number of clusters:', optimal_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot Silhouette scores\n",
    "# plt.plot(range(2,11), sil_scores)\n",
    "# plt.title('Silhouette Scores')\n",
    "# plt.xlabel('Number of Clusters')\n",
    "# plt.ylabel('Silhouette Score')\n",
    "# plt.show()\n",
    "\n",
    "# # Generate plot with each wine represented as a dot in a 2D space in the color of its cluster\n",
    "# kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "# cluster_labels = kmeans.fit_predict(embedding)\n",
    "# cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "# plt.scatter(embedding[:, 0], embedding[:, 1], c=cluster_labels, cmap='viridis')\n",
    "# plt.scatter(cluster_centers[:, 0], cluster_centers[:, 1], marker='x', s=200, linewidths=3, color='r')\n",
    "# plt.title('t-SNE Embedding with {} Clusters'.format(optimal_k))\n",
    "# plt.show()\n",
    "\n",
    "# # Compute sum of distances of all points to their respective cluster centers\n",
    "# distances = cdist(embedding, cluster_centers, 'euclidean')\n",
    "# min_distances = np.min(distances, axis=1)\n",
    "# sum_distances = np.sum(min_distances)\n",
    "\n",
    "# print('Total sum of distance of all points to their respective cluster centers:', sum_distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# p50/lactate impact on mortality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if there is significant correlation between this and lactate\n",
    "Anion Gap (bmp_aniongap) – High anion gap is associated with poor outcomes. Will have to see if there is significant correlation between this and lactate. If there is significant correlation, only pick lactate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Select the relevant variables for correlation check\n",
    "variables_to_check = ['bmp_aniongap', 'bmp_lactate']\n",
    "\n",
    "# Create a subset DataFrame with the selected variables\n",
    "subset_data = data[variables_to_check]\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = subset_data.corr()\n",
    "\n",
    "# Print the correlation matrix\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A correlation coefficient of 0.322272 indicates that there is some positive relationship between 'bmp_aniongap' and 'bmp_lactate', but it's not extremely strong. Therefore, we will keep both features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the logistic regression model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Select the relevant variables\n",
    "variables = ['BMI_admission', 'sex_female', 'admission_age', 'p50', 'sofa_past_overall_24hr', 'cbc_hemoglobin', 'bmp_aniongap', 'bmp_lactate', 'bmp_sodium', 'hfp_alt', 'in_hospital_mortality','pO2', 'SpO2', 'pH', 'pCO2', 'vitals_tempc', 'race_ethnicity_Asian', 'race_ethnicity_Black', 'race_ethnicity_Hispanic OR Latino', 'race_ethnicity_More Than One Race', 'race_ethnicity_Native Hawaiian / Pacific Islander', 'race_ethnicity_Unknown', 'race_ethnicity_White']\n",
    "\n",
    "# Create a subset DataFrame with the selected variables\n",
    "subset_data = data[variables].copy()\n",
    "\n",
    "# Add a constant term for the intercept in the logistic regression\n",
    "subset_data = sm.add_constant(subset_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note on adding a constant term for the intercept in the logistic regression: \n",
    "* The intercept term represents the value of the dependent variable when all independent variables are zero. It's an important part of the model and accounts for the vertical shift of the regression line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the predictors (independent variables) and the target (dependent variable)\n",
    "X = subset_data.drop('in_hospital_mortality', axis=1)\n",
    "y = subset_data['in_hospital_mortality']\n",
    "\n",
    "# Fit the logistic regression model\n",
    "logit_model = sm.Logit(y, X)\n",
    "result = logit_model.fit()\n",
    "\n",
    "# Print the summary of the regression\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the printed summary, you can find the coefficients for 'lactate' and 'p50'. Pay attention to the coefficients' values, standard errors, and p-values. The magnitude and significance of these coefficients will help you assess the predictive power of 'lactate' versus 'p50' in predicting mortality. If a coefficient has a larger magnitude and a lower p-value, it suggests a stronger influence on the outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Variables with p-values close to 0 (e.g., 'admission_age', 'sofa_past_overall_24hr', 'cbc_hemoglobin', 'bmp_aniongap', 'bmp_lactate', 'pO2', 'SpO2', 'pH', 'pCO2', 'vitals_tempc') are likely to have a statistically significant impact on the outcome ('in_hospital_mortality').\n",
    "\n",
    "* Variables with higher p-values (e.g., 'sex_female', 'race_ethnicity' categories) might not be statistically significant predictors in this model.\n",
    "\n",
    "* Negative coefficients indicate a decrease in the log-odds of the outcome, while positive coefficients indicate an increase, for a one-unit increase in the predictor.\n",
    "\n",
    "* The confidence intervals provide a range within which you can be reasonably confident the true coefficient lies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract coefficient estimates and confidence intervals\n",
    "coef = result.params\n",
    "conf_int = result.conf_int()\n",
    "\n",
    "# Create a bar plot of coefficients\n",
    "plt.figure(figsize=(10, 6))\n",
    "coef.plot(kind='bar', yerr=(coef - conf_int[0], conf_int[1] - coef), color='blue', alpha=0.7)\n",
    "plt.title('Logistic Regression Coefficients')\n",
    "plt.xlabel('Variables')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a predictive model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train the logistic regression model with both 'lactate' and 'p50' as predictor variables.\n",
    "* Examine the coefficients of 'lactate' and 'p50' to understand their individual impacts on the log-odds of mortality.\n",
    "* Compare the coefficients and their significance to assess the relative predictive power of 'lactate' and 'p50'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Build a baseline model using the selected features to predict mortality (without p50) \n",
    "This is the model that uses only the SOFA score to predict mortality. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the focus on comparing the predictive power of \"p50\" with SOFA score, we are starting with the baseline features that are commonly used for predicting mortality:\n",
    "* SOFA score: \"sofa_past_overall_24hr\"\n",
    "* Comorbidity score: \"comorbidity_score_value\"\n",
    "* Hemoglobin: \"cbc_hemoglobin\"\n",
    "* Anion Gap: \"bmp_aniongap\"\n",
    "* Lactate: \"bmp_lactate\"\n",
    "* Sodium: \"bmp_sodium\"\n",
    "* ALT: \"hfp_alt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Select the relevant variables\n",
    "predictor_vars = ['sofa_past_overall_24hr', 'comorbidity_score_value','cbc_hemoglobin','bmp_aniongap', 'bmp_lactate', 'bmp_sodium', 'hfp_alt']\n",
    "\n",
    "target_var = 'in_hospital_mortality'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[predictor_vars]\n",
    "y = data[target_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Count the occurrences of each class\n",
    "class_counts = data['in_hospital_mortality'].value_counts()\n",
    "\n",
    "# Calculate the total number of samples\n",
    "total_samples = len(data)\n",
    "\n",
    "# Calculate the percentage of each class\n",
    "class_percentages = class_counts / total_samples * 100\n",
    "\n",
    "# Print the class distribution with percentages\n",
    "for class_label, count in class_counts.items():\n",
    "    percentage = class_percentages[class_label]\n",
    "    print(f\"Class {class_label}: Count = {count}, Percentage = {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and test data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create a logistic regression model\n",
    "logit_model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "logit_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# to do show the weights - how it is done in clinical papers.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on the test set\n",
    "# Predict probabilities on the testing set\n",
    "y_pred_probs = logit_model.predict_proba(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_probs will be an array with two columns: [probability_of_class_0, probability_of_class_1]\n",
    "# In your case, you're interested in the probability of class 1 (mortality)\n",
    "predicted_mortality_probs = y_pred_probs[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using predicted probabilities (you need to set a threshold)\n",
    "threshold = 0.5  # You can adjust the threshold based on your requirements\n",
    "y_pred = (predicted_mortality_probs > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Assuming you have y_test containing the actual ground truth labels\n",
    "# y_pred contains the predicted binary class labels after applying the threshold\n",
    "\n",
    "# Evaluate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Assuming  X_train, X_test, y_train, y_test are already prepared\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'SVM': SVC(class_weight='balanced', probability=True)  # Note: SVM needs probability estimates for ROC-AUC\n",
    "}\n",
    "\n",
    "# Initialize dictionaries to store performance metrics\n",
    "metrics = {'Model': [], 'Accuracy': [], 'Precision': [], 'Recall': [], 'F1-Score': [], 'AUC-ROC': []}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_prob = model.predict_proba(X_test_scaled)[:, 1]  # Probability estimates for ROC-AUC\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "    \n",
    "    metrics['Model'].append(model_name)\n",
    "    metrics['Accuracy'].append(accuracy)\n",
    "    metrics['Precision'].append(precision)\n",
    "    metrics['Recall'].append(recall)\n",
    "    metrics['F1-Score'].append(f1)\n",
    "    metrics['AUC-ROC'].append(roc_auc)\n",
    "\n",
    "# Create a pandas DataFrame from the metrics\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Display the metrics in a table\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Enhanced Model with \"p50\"\n",
    "This is the model that includes the variable p50 in addition to the SOFA score to predict mortality. You will need to train, evaluate, and compare the performance of this enhanced model to the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Select the relevant variables\n",
    "predictor_vars = ['p50','sofa_past_overall_24hr', 'comorbidity_score_value' ,'cbc_hemoglobin','bmp_aniongap', 'bmp_lactate', 'bmp_sodium', 'hfp_alt']\n",
    "\n",
    "target_var = 'in_hospital_mortality'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X = data[predictor_vars]\n",
    "y = data[target_var]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and test data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create a logistic regression model\n",
    "logit_model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "logit_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on the test set\n",
    "# Predict probabilities on the testing set\n",
    "y_pred_probs = logit_model.predict_proba(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_probs will be an array with two columns: [probability_of_class_0, probability_of_class_1]\n",
    "# In your case, you're interested in the probability of class 1 (mortality)\n",
    "predicted_mortality_probs = y_pred_probs[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using predicted probabilities (you need to set a threshold)\n",
    "threshold = 0.5  # You can adjust the threshold based on your requirements\n",
    "y_pred = (predicted_mortality_probs > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Assuming you have y_test containing the actual ground truth labels\n",
    "# y_pred contains the predicted binary class labels after applying the threshold\n",
    "\n",
    "# Evaluate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Assuming  X_train, X_test, y_train, y_test are already prepared\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42,class_weight='balanced'),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'SVM': SVC(random_state=42, class_weight='balanced', probability=True)  # Note: SVM needs probability estimates for ROC-AUC\n",
    "}\n",
    "\n",
    "# Initialize dictionaries to store performance metrics\n",
    "metrics = {'Model': [], 'Accuracy': [], 'Precision': [], 'Recall': [], 'F1-Score': [], 'AUC-ROC': []}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_prob = model.predict_proba(X_test_scaled)[:, 1]  # Probability estimates for ROC-AUC\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "    \n",
    "    metrics['Model'].append(model_name)\n",
    "    metrics['Accuracy'].append(accuracy)\n",
    "    metrics['Precision'].append(precision)\n",
    "    metrics['Recall'].append(recall)\n",
    "    metrics['F1-Score'].append(f1)\n",
    "    metrics['AUC-ROC'].append(roc_auc)\n",
    "\n",
    "# Create a pandas DataFrame from the metrics\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Display the metrics in a table\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down the results for predicting mortality (a binary outcome) using the provided metrics:\n",
    "\n",
    "1. **Random Forest:**\n",
    "   - **Accuracy (0.830786):** Out of all predictions made by the model, around 83% are correct. This might seem good, but...\n",
    "   - **Precision (0.638037):** Only about 64% of the instances that the model classified as positive (mortality) are actually true positives. This means there are a lot of false positive predictions.\n",
    "   - **Recall (0.125150):** The model captures only about 13% of the actual positive instances. This means it's missing a substantial portion of cases where mortality is true.\n",
    "   - **F1-Score (0.209256):** The F1-score takes into account both precision and recall. It's the harmonic mean of the two and provides a balance between them. A low F1-score indicates an imbalance between precision and recall.\n",
    "   - **AUC-ROC (0.720081):** The AUC-ROC score measures the model's ability to distinguish between the two classes. A score of 0.72 suggests moderate discriminative power.\n",
    "\n",
    "2. **Gradient Boosting:**\n",
    "   - **Accuracy (0.831647):** Again, around 83% of the predictions are correct, but...\n",
    "   - **Precision (0.621891):** About 62% of the positive predictions are true positives, while...\n",
    "   - **Recall (0.150421):** Only around 15% of the actual positive instances are captured.\n",
    "   - **F1-Score (0.242248):** The F1-score is higher than the Random Forest but still relatively low, indicating a trade-off between precision and recall.\n",
    "   - **AUC-ROC (0.737686):** The AUC-ROC score is slightly higher, indicating slightly better classification performance compared to the Random Forest.\n",
    "\n",
    "3. **SVM:**\n",
    "   - **Accuracy (0.720775):** The accuracy drops to 72%, but...\n",
    "   - **Precision (0.338419):** Only about 34% of the positive predictions are true positives.\n",
    "   - **Recall (0.587244):** The model captures around 59% of the actual positive instances.\n",
    "   - **F1-Score (0.429388):** The F1-score is relatively higher, indicating a balance between precision and recall.\n",
    "   - **AUC-ROC (0.716942):** The AUC-ROC score suggests moderate discriminative power.\n",
    "\n",
    "In summary, while accuracy might seem acceptable, the models are struggling to accurately predict the positive class (mortality). The Precision-Recall trade-off is a common challenge when dealing with imbalanced datasets. Depending on the specific problem and domain, you might need to prioritize either precision (minimizing false positives) or recall (capturing true positives) more. Evaluating the models using multiple metrics provides a better understanding of their performance. If capturing true positive cases (mortality) is particularly important, you might focus more on improving recall, even if it means accepting a slightly lower precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAKES 8min 10s TO RUN \n",
    "\n",
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Assuming X and y are already prepared\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'SVM': SVC(random_state=42, class_weight='balanced', probability=True)\n",
    "}\n",
    "\n",
    "# Initialize dictionaries to store performance metrics\n",
    "metrics = {'Model': [], 'Accuracy': [], 'Precision': [], 'Recall': [], 'F1-Score': [], 'AUC-ROC': []}\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "n_splits = 5\n",
    "cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Train and evaluate each model using cross-validation\n",
    "for model_name, model in models.items():\n",
    "    y_pred_cv = cross_val_predict(model, X, y, cv=cv)\n",
    "    y_prob_cv = cross_val_predict(model, X, y, cv=cv, method='predict_proba')[:, 1]\n",
    "\n",
    "    accuracy = accuracy_score(y, y_pred_cv)\n",
    "    precision = precision_score(y, y_pred_cv)\n",
    "    recall = recall_score(y, y_pred_cv)\n",
    "    f1 = f1_score(y, y_pred_cv)\n",
    "    roc_auc = roc_auc_score(y, y_prob_cv)\n",
    "    \n",
    "    metrics['Model'].append(model_name)\n",
    "    metrics['Accuracy'].append(accuracy)\n",
    "    metrics['Precision'].append(precision)\n",
    "    metrics['Recall'].append(recall)\n",
    "    metrics['F1-Score'].append(f1)\n",
    "    metrics['AUC-ROC'].append(roc_auc)\n",
    "\n",
    "# Create a pandas DataFrame from the metrics\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Display the metrics in a table\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (ml)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1db5eb8bcb554b879e6eae872be3ec4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f66bce592cf4e969f1469f6e98eebea",
      "placeholder": "​",
      "style": "IPY_MODEL_bfe5965b21ec4734b51fdcb645a01340",
      "value": "Summarize dataset:   1%"
     }
    },
    "30c584cfbac2489fbe55f6b1280baa30": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f16b8392a074baebaa06dd87007e467": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f66bce592cf4e969f1469f6e98eebea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7918f85bc2cc472fa390935b90671eae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f16b8392a074baebaa06dd87007e467",
      "max": 5,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e77ccf0fc56b4ae89b33c7fccadb9f27",
      "value": 5
     }
    },
    "bfe5965b21ec4734b51fdcb645a01340": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d063b5b532b64e1dace7175d4693aadc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef363f165a764753ab0a6183e7862db9",
      "placeholder": "​",
      "style": "IPY_MODEL_eacccf2ec5844c928350d5df7c1ee21e",
      "value": " 197/13838 [02:22&lt;1:01:35,  3.69it/s, scatter delta_cbc_rdw, unique_subject_id]"
     }
    },
    "e77ccf0fc56b4ae89b33c7fccadb9f27": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ea0a43ac205a439ea27515369eaa103e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1db5eb8bcb554b879e6eae872be3ec4a",
       "IPY_MODEL_7918f85bc2cc472fa390935b90671eae",
       "IPY_MODEL_d063b5b532b64e1dace7175d4693aadc"
      ],
      "layout": "IPY_MODEL_30c584cfbac2489fbe55f6b1280baa30"
     }
    },
    "eacccf2ec5844c928350d5df7c1ee21e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ef363f165a764753ab0a6183e7862db9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
